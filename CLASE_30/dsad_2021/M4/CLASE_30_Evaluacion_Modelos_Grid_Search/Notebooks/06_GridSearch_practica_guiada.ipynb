{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/csuarezgurruchaga/Desktop/Digital-House/CLASE_30/dsad_2021/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "Running command `conda install --yes nltk=3.5.0`... ok\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n",
    "\n",
    "from checkpoint_grid_search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center><ins>GRID SEARCH y RANDOM SEARCH</ins></center></h1>\n",
    "<h1><center>Práctica guiada:</center></h1>\n",
    "<img src=\"img/01_gs.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tabla_contenidos\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "### <a href='#section_objetivos'>0. Objetivos de la Notebook</a>\n",
    "\n",
    "\n",
    "### <a href='#section_repaso'>1. Introducción</a>\n",
    "- #### <a href='#section_hiperparametros'>1.1 ¿Qué son los hiperparámetros de un modelo?</a>\n",
    "- #### <a href='#section_gs_rs'>1.2 GridSearch y RandomSearch: estrategias para definir hiperparámetros</a>\n",
    "- #### <a href='#1.3'>1.3 Repaso hiperparámetros modelos</a>\n",
    "- #### <a href='#1.4'>1.4 Receta general</a>\n",
    "\n",
    "### <a href='#2.'>2. Manos a la obra: busquemos hiperparámetros</a>\n",
    "- #### <a href='#2.1'>2.1 Cargar y preparar dataset</a>\n",
    "- #### <a href='#2.2'>2.2 Probamos hiperparámetros \"a mano\"</a>\n",
    "- #### <a href='#2.3'>2.3 Usando GridSearchCV</a>\n",
    "- #### <a href='#2.4'>2.4 Usando RandomizedSearchCV</a>\n",
    "\n",
    "### <a href='#3.'>3. Comentarios finales</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_objetivos\"></a> \n",
    "## 0. Objetivos de la Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja11\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 9%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\">\n",
    "      <label>Conocer un método para determinar hiper-parámetros: </label>\n",
    "      <a class=\"reference internal\" href=https://scikit-learn.org/stable/modules/grid_search.html><b><code>GridSearch</code>         </b></a>\n",
    "  <div style=\"float:left;width: 85%;\">\n",
    "      <label>Comparar dos aproximaciones para la búsqueda de hiperparámetros óptimos para un modelo:</label>    \n",
    "      <a class=\"reference internal\" href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html><b><code>GridSearch</code></b></a><label> y </label><a class=\"reference internal\" href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html><b><code>RandomSearch</code>\n",
    "      </b></a>\n",
    "   <br>\n",
    "   <div style=\"float:left;width: 85%;\">\n",
    "      <label>Implementar <code>GridSearch</code> y <code>RandomSearch</code> de <b>sklearn</b> para autoajustar un modelo.</label>\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#tabla_contenidos'>Volver a TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_repaso\"></a> \n",
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_hiperparametros\"></a> \n",
    "### 1.1 ¿Qué son los hiperparámetros de un modelo?\n",
    "\n",
    "Los **hiperparámetros** son aquella/s característica/s externas de un modelo que no se \"aprenden\" de forma directa a partir del entrenamiento con los datos. \n",
    "\n",
    "Son **valores** que tiene que definirse cuando se implementa el modelo, antes de realizar el entrenamiento.\n",
    "\n",
    "Un ejemplo de **hiperparámetro** es el valor **k** en el algoritmo [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). \n",
    "\n",
    "Por otro lado, un **parámetro** de un modelo es una característica o propiedad interna cuyo valor es estimado a partir del entrenamiento con los datos. Un ejemplo de estos, son los **coeficientes** de una **regresión lineal** o **logística**.\n",
    "\n",
    "\n",
    "Los **hiperparámetros** son muy importantes a la hora de entrenar un modelo ya que van a impactar en su desempeño y no se puede saber **a priori** cuáles son los mejores **hiperparámetros** para elegir en función del problema con el que estamos lidiando. \n",
    "Además, mientras que para un modelo una **configuración específica de hiperparámetros** puede presentar un excelente desempeño en determinado problema, en otro contexto ese mismo modelo con la misma configuración de hiperparámetros puede ser que no represente la solución de mejor rendimiento. Así que contar con estrategias para definir los **hiperparámetros** de un modelo es de suma importancia en machine-learning:\n",
    "\n",
    "<img src=\"img/02_gs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>HINT para no olvidar:</b> recuerden que los <b>hiperparámetros</b> con las características del modelo que vamos a poder tunear a través de <code>GridSearch</code> y <code>RandomSearch</code>, por ejemplo, y que son elegidas a priori por nosotros. Mientras que los <b>parámetros de un modelo</b>, es lo que el modelo aprende durante el entrenamiento (como por ejemplo los coeficientes beta de una regresión lineal)</label></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"img/02_hiper.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_gs_rs\"></a> \n",
    "### 1.2 GridSearch y RandomSearch: estrategias para definir hiperparámetros\n",
    "\n",
    "Existen dos grandes métodos o procesos (aunque no son los únicos) que nos permiten buscar cuáles son los mejores **hiperparámetros** en nuestro problema (**hyper-parameter tunning**): [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) y [`RandomSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html):\n",
    "\n",
    "\n",
    "\n",
    "[`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) se basa en buscar la mejor combinación de **hiperparámetros** dentro de una **grilla (grid)** especificada previamente. Lo que caracteriza esta estrategia es que la búsqueda es **exhaustiva para cada valor de la grilla** y se elige la combinación de **hiperparámetros** que minimizan una determinada métrica de error, como puede ser el **accuracy** en un problema de clasificación o el **coeficiente de determinación** (R2) en uno de regresión. Esta estrategia se denomina **grid** porque su idea es hacer un **retículo** con todos los **hiperparámetros** definidos en la grilla y sus resultados en el modelo.\n",
    "\n",
    "[`RandomSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) dado que el **GridSearch** implica una búsqueda exhaustiva de todas las combinaciones posibles de la grilla de **hiperparámetros** especificada, su ejecución pude volverse computacionalmente muy intensa (en particular si estamos haciendo una búsqueda por una gran cantidad de **hiperparámetros**). Con la estrategia de **RandomSearch** se realiza la búsqueda de la mejor combinación de **hiperparámetros** pero a partir de seleccionar en forma **aleatoria** un **subset** de los **hiperparámetros**, lo que achia el espacio de búsqueda.\n",
    "\n",
    "<img src=\"img/03_gs_bis.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Si tomamos como ejemplo lo que plantea esta figura, podemos distinguir claramente las diferencias entre ambas estrategias. Mientras que en [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) se van a evaluar todas las combinaciones de las opciones de cada uno de los dos **hiperparámetros** (dado que en la grilla de cada uno de ellos se definen tres valores, entonces vamos a tener un total de 9 opciones para evaluar); en [`RandomSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) se van a evaluar un **sub-set de combinaciones** de esa misma grilla seleccionadas en forma **aleatoria** (así, por ejemplo, en este caso quedan 6 opciones para ser evaluadas). \n",
    "\n",
    "**¿Cómo hacen estas estrategias para hacer la búsqueda de hiperparámetros?**:\n",
    "Ambas estrategias, para determinar cuál es la combinación óptima de **hiperparámetros**, se basan en entrenar y validar el modelo seleccionado con cada una de estas posibles combinaciones a partir de estrategias de **cross-validation**: \n",
    "\n",
    "<img src=\"img/04_gs.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "En el esquema anterior, se observa que:\n",
    "- primero se va a separar la data para quedarnos con un subconjunto de datos (**test**) para evaluar el poder de **generalización** de nuestro modelo (**holdout sets**).\n",
    "- Luego, los datos de **train** van a ser utilizados para seleccionar la mejor combinación de **hiperparámetros** a partir de una estrategia de **cross-validation** con 5-folds. Es decir que cada **combinación de hiperparámetros** de toda la grilla (en el caso de **GridSearch**) o del subset elegido aleatoriamente de la misma (en el caso de **RandomSearch**), va a ser validado mediante este esquema de **cross-validation**. \n",
    "- Además, estas estrategias nos van a permitir elegir cuál es la **métrica de evaluación** que queremos utilizar como objetivo. Si en un problema de clasificación tenemos un dataset balanceado, podemos utilizar el **accuracy**; o si el dataset llega a tener un problema de desbalanceo de clases, podemos utilizar el **recall** para que la estrategia de búsqueda priorice la combinación de **hiperparámetros** que menos errores cometa identificando a los **True positive**. \n",
    "- Por último, la **mejor combinación de hiperparámetros** la vamos a volver a entrenar con todo nuestro conjunto de datos de **train** y vamos a evaluar su poder de generalización con los datos de **test** que nos guardamos en el primer paso (**holdout sets**). \n",
    "\n",
    "\n",
    "\n",
    "Teniendo en cuenta el esquema de **cross-validation** que se va a aplicar tanto para **GridSearch** como para **RandomSearch**, ¿qué problema podríamos tener si usamos un modelo con **muchos hiperparámetros** y, a su vez, para cada **hiperparámetro** queremos evaluar un rango muy extenso de posibles valores: \n",
    "<img src=\"img/05_gs.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Y sí, vamos a tener un **\"bad time\"** porque computacionalmente puede tornarse muy costoso a nivel de cómputo estar haciendo la evalaución de todas las combinaciones posibles de los valores de los **hiperparámetros**. Por esa razón, en algunos casos vamos a tener que elegir una **grilla reducida** de **hiperparámetros**, o utilizar **RandomSearch** que al elegir un subset de combinaciones va a generar un costo de cómputo mucho menor y nos va a brindar resultados con mayor rapidez. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/ponete_a_prueba.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Entonces... </b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La estrategia de GridSearch:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f8d3de9b0f4868b202e1f3a5b6bcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(width='100%'), options=('Hace una búsqueda exhaustiva de los parámetros del modelo.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50954dbb8d74c56bdc3a68636c4bc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Validar', style=ButtonStyle(), tooltip='Click para validar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40034b128ab74a64a4b559b2458ad2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecutá esta celda...\n",
    "test_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.3\"></a>\n",
    "### 1.3 Repaso hiperparámetros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/06_hyp.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión lineal**:\n",
    "- En Scikit la decisión sobre si el modelo tiene o no intercepto. \n",
    "- Documentación:[`Regresión lineal`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "***\n",
    "\n",
    "**Regresiones Ridge, Lasso y Elastic Net:**\n",
    "- El principal es **alpha** (a veces llamado lambda) que regula cuánto se penaliza el valor de los coeficientes. A mayor **alpha** (lambda) se produce un mayor sesgo y menor varianza.\n",
    "- Documentación:[`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html),[`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html), [`Elastic Net`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)  \n",
    "***\n",
    "\n",
    "**K Nearest Neighbors (KNN):**\n",
    "- Los dos principales son: \n",
    "    - k: la cantidad de vecinos. A mayor K, mayor sesgo y menor varianza.\n",
    "    - weight: si queremos ponderar más a algunos vecinos que a otros de los contemplados por el valor K.\n",
    "- Documentación:[`KNN`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "***\n",
    "\n",
    "**Regresión logística:**\n",
    "- El principal es **C** que es la inversa de la fuerza de regularización. Mientras más pequeño sea el valor, más fuerte va a ser la regularización (CUIDADO: por default viene en 1, lo que implica que va a regularizar; si queremos reducir la regularización tenemos que reemplazarlo por un número muy grande). A mayor C, menor sesgo y mayor varianza. \n",
    "- Documentación:[`Regresión logística`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "***\n",
    "\n",
    "**Naive Bayes:**\n",
    "- Tiene hiperparámetros pero que no suelen ajustarse. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.4\"></a>\n",
    "### 1.4 Receta general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de implementar en `sklearn` una búsqueda sobre **hiperparámetros** tenemos que tener en cuenta las siguientes cuestiones:\n",
    "- Elegir un **estimador**, es decir, un modelo sobre el cual queremos trabajar.\n",
    "- Elegir un **espacio de parámetros** donde vamos a hacer la búsqueda.\n",
    "- Elegir un **método de busqueda** sobre los modelos candidatos (`RandomSearch`,`GridSearch`).\n",
    "- Implementar un **esquema de validación cruzada**, donde se deben elegir la cantidad de particiones.\n",
    "- La **métrica de evaluación** para elegir el mejor modelo... y ¡gualá!\n",
    "\n",
    "<img src=\"img/06_receta.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#tabla_contenidos'>Volver a TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.\"></a> \n",
    "## 2. Manos a la obra: busquemos hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "### 2.1 Cargar y preparar el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar **GridSearch** y **RandomSearch** sobre un set de datos adaptados de una competencia de kaggle ya cerrada: https://www.kaggle.com/kevinmh/fifa-18-more-complete-player-dataset\n",
    "\n",
    "En el dataset vamos a encontrar todos los jugadores de fútbol argentino que están en el juego fifa-18, y contaremos con las siguientes variables: \n",
    "- **ID**: un número único que identifica al jugador en toda la base.\n",
    "- **full_name**: nombre completo del jugador.\n",
    "- **age**\n",
    "- **club**: del jugador\n",
    "- **height_cm**\n",
    "- **weight_kg**\n",
    "- **puntaje_global**: puntaje que identifica la habilidad general del jugador, vamos a contar con tres categorías de nivel: bajo, medio y alto.\n",
    "- **potencia**: potencia física del jugador.\n",
    "- **ritmo**: velocidad de aceleración del jugador.\n",
    "- **disparos**: nivel de precisión y potencia de sus remates.\n",
    "- **pases**: nivel de precisión en sus pases.\n",
    "- **amagues**: nivel de habilidad para amagar a un rival.\n",
    "- **defensa**: capacidad defensiva general del jugador.\n",
    "- **físico**: estado físico del jugador (nos indicaría qué tan rápido se cansa)\n",
    "\n",
    "El **objetivo** del dataset es utilizar distintas features vinculadas al jugador para poder predecir qué nivel global tiene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/ponete_a_prueba.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Entonces... </b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estamos planteando un problema de machine-learning de qué tipo?:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e694187743a445119945fb3ab9ce3477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(width='100%'), options=('Clasificación', 'Regresión', 'Reducción de la dimensionali…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e743bd5e5414e43af1e41cd2c8b9d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Validar', style=ButtonStyle(), tooltip='Click para validar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3d9d817ec44cbaf98735b80bf055f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutá esta celda..\n",
    "test_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos cómo usar `GridSearchCV` para tunear el hiperparámetro `k` del algoritmo de vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, importamos las librerías que hemos visto en módulos pasados y cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>full_name</th>\n",
       "      <th>club</th>\n",
       "      <th>age</th>\n",
       "      <th>league</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>puntaje_global</th>\n",
       "      <th>potencia</th>\n",
       "      <th>ritmo</th>\n",
       "      <th>disparos</th>\n",
       "      <th>pases</th>\n",
       "      <th>amagues</th>\n",
       "      <th>defensa</th>\n",
       "      <th>físico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158023</td>\n",
       "      <td>Lionel Messi</td>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>30</td>\n",
       "      <td>Spanish Primera División</td>\n",
       "      <td>170.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>alto</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167664</td>\n",
       "      <td>Gonzalo Higuaín</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>29</td>\n",
       "      <td>Italian Serie A</td>\n",
       "      <td>184.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>alto</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153079</td>\n",
       "      <td>Sergio Agüero</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>29</td>\n",
       "      <td>English Premier League</td>\n",
       "      <td>173.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>alto</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>211110</td>\n",
       "      <td>Paulo Dybala</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>23</td>\n",
       "      <td>Italian Serie A</td>\n",
       "      <td>177.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>alto</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>183898</td>\n",
       "      <td>Ángel Di María</td>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>29</td>\n",
       "      <td>French Ligue 1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>alto</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        full_name                 club  age  \\\n",
       "1   158023     Lionel Messi         FC Barcelona   30   \n",
       "9   167664  Gonzalo Higuaín             Juventus   29   \n",
       "16  153079    Sergio Agüero      Manchester City   29   \n",
       "19  211110     Paulo Dybala             Juventus   23   \n",
       "85  183898   Ángel Di María  Paris Saint-Germain   29   \n",
       "\n",
       "                      league  height_cm  weight_kg puntaje_global  potencia  \\\n",
       "1   Spanish Primera División      170.0       72.0           alto        93   \n",
       "9            Italian Serie A      184.0       87.0           alto        90   \n",
       "16    English Premier League      173.0       70.0           alto        89   \n",
       "19           Italian Serie A      177.0       73.0           alto        93   \n",
       "85            French Ligue 1      180.0       75.0           alto        85   \n",
       "\n",
       "    ritmo  disparos  pases  amagues  defensa  físico  \n",
       "1      89        90     86       96       26      61  \n",
       "9      79        87     70       83       25      74  \n",
       "16     87        88     75       89       23      72  \n",
       "19     86        85     81       91       24      67  \n",
       "85     86        77     82       86       47      68  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/fifa_18_jugadores_argentinos.csv',index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corroboramos que no haya valores faltantes en nuestro dataset y verificamos el tipo de dato de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 962 entries, 1 to 17912\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              962 non-null    int64  \n",
      " 1   full_name       962 non-null    object \n",
      " 2   club            962 non-null    object \n",
      " 3   age             962 non-null    int64  \n",
      " 4   league          962 non-null    object \n",
      " 5   height_cm       962 non-null    float64\n",
      " 6   weight_kg       962 non-null    float64\n",
      " 7   puntaje_global  962 non-null    object \n",
      " 8   potencia        962 non-null    int64  \n",
      " 9   ritmo           962 non-null    int64  \n",
      " 10  disparos        962 non-null    int64  \n",
      " 11  pases           962 non-null    int64  \n",
      " 12  amagues         962 non-null    int64  \n",
      " 13  defensa         962 non-null    int64  \n",
      " 14  físico          962 non-null    int64  \n",
      "dtypes: float64(2), int64(9), object(4)\n",
      "memory usage: 120.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos la matriz de predictores ($X$) (vamos a seleccionar sólo las columnas numéricas) y el target ($y$) (que es el nivel de puntaje total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['age','height_cm','weight_kg','potencia','ritmo','disparos','pases','amagues','defensa','físico']\n",
    "X = df[cols]\n",
    "y = df['puntaje_global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos fijamos la distribución de las etiquetas para evaluar si hay un desbalanceo en las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medio    0.376299\n",
       "alto     0.347193\n",
       "bajo     0.276507\n",
       "Name: puntaje_global, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La distribución es relativamente pareja entre las tres clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test (y por las dudas usamos el argumento de **stratify** para mantener la proporción de los niveles en los datos de train y test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(193, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(769,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=56)\n",
    "display(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Hace falta estandarizar en este caso? Los features están en las mismas unidades pero las escalas podrían ser distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos sklearn para estandarizar la matriz de Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>HINT para no olvidar:</b> recuerden que siempre que estamos aplicando transformaciones sobre nuestros datos que dependen de estos (como la normalización), las transformaciones se entrenan con los datos de <b>train</b> sin incluir los de <b>test</b>, y sobre estos últimos se aplica la transformación ya entrenada. Por eso usamos <code>scaler.fit_transform(X_train)</code> para <b>train</b> pero sólo el método <code>scaler.transform(X_test)</code> para <b>test</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "### 2.2 Probamos hiperparámetros \"a mano\"\n",
    "Está claro que, dependiendo del modelo, los hiperparámetros pueden tener un efecto importante en la calidad de la predicción. \n",
    "Veamos cómo varía el accuracy a la hora de predecir el nivel del futbolista para **distintos valores de K**.\n",
    "\n",
    "Para esto vamos a usar [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) que nos permite evaluar los resultados de una métrica (el accuracy en este caso) en un esquema de validación cruzada. \n",
    "\n",
    "Vamosa utilizar 10 folds en `cross_val_score` pero para definir este número vamos a usar [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) una clase de **sklearn** que nos asegura que cada fold va contar con casos seleccionados en forma aleatoria pero que van a mantener la distribución original de las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7697368421052632,\n",
       " 0.7568010936431989,\n",
       " 0.8232228298017772,\n",
       " 0.816660970608339,\n",
       " 0.824436090225564,\n",
       " 0.8465311004784688,\n",
       " 0.8322112098427887,\n",
       " 0.8399521531100479,\n",
       " 0.8399863294600136,\n",
       " 0.8412679425837319,\n",
       " 0.8438824333561176,\n",
       " 0.8464969241285031,\n",
       " 0.8426179084073822,\n",
       " 0.850393028024607,\n",
       " 0.85041011619959,\n",
       " 0.8504101161995898,\n",
       " 0.8426349965823651,\n",
       " 0.8517429938482571,\n",
       " 0.8400205058099794,\n",
       " 0.8504613807245386,\n",
       " 0.8504784688995215,\n",
       " 0.8543403964456596,\n",
       " 0.846514012303486,\n",
       " 0.855622009569378,\n",
       " 0.8452323991797677,\n",
       " 0.8529904306220095,\n",
       " 0.8361244019138756,\n",
       " 0.8387218045112782,\n",
       " 0.8413362952836637,\n",
       " 0.8361244019138756]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_splits = permite determinar la cantidad de folds\n",
    "# random_state = nos permite definir una semilla para asegura reproducibilidad\n",
    "# shuffle = nos asegura que las particiones se van a hacer en forma aleatoria\n",
    "folds=StratifiedKFold(n_splits=10, random_state=19, shuffle=True)\n",
    "\n",
    "# Hacemos un for para recorrer distintos valores de K y evaluamos los scores de la validación cruzada de los datos de train.\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=folds, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lista encontramos los valores de **accuracy** que obtuvimos en la validación cruzada para cada uno de los distintos valores de **k**.\n",
    "\n",
    "Grafiquemos estos resultados para ver más claro cuál es el **k** óptimo según esta validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, observamos que la performance cambia para distintos valores del hiperparámetro, siendo que el **k** óptimo es el de 23, con un score de validación de 0.855634.\n",
    "\n",
    "\n",
    "¿Cómo podemos hacer para sistematizar esta búsqueda y sumar más hiperparámetros a la exploración? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "### 2.3 Usando [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello vamos a importar el método [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) que básicamente va a implementar en forma automática lo que acabamos de hacer en forma manual.\n",
    "\n",
    "**Documentación:** [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) \n",
    "\n",
    "Es decir, nos va a permitir implementar una estrategia de validación cruzada en la cual va a realizar tantas validaciones como combinaciones posibles de hiperarámetros querramos evaluar (ya que recuerden que el `GridSearchCV` hace una búsqueda exhaustiva del espacio de hiperparámetros). \n",
    "\n",
    "Por ejemplo, de [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) podríamos querer explorar la combinación entre dos valores de vecinos (k: [2,5]) y las dos formas de considerar la influencia de los veciones entre sí (weights: [uniform, distance]). Ante este escenario, el [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) va aplicar una estrategia de validación por cada combinación de estos dos hiperparámetros: [2,uniform],[2,distance],[5,uniform], [5,distance]. Por cada una de estas combinaciones, `GridSearchCV` va aplicar una estrategia de validación cruzada (con la cantidad de folds que le indiquemos).\n",
    "\n",
    "[`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) va a necesitar 4 argumentos iniciales: \n",
    "- **estimator =**un estimador (es decir, modelo instanciado)\n",
    "- **param_grid=** una grilla de parametros para recorrer (que tiene que ser un diccionario cuyas claves correspondan a los hiperparámetros del modelo y los valores sean listas de valores que va a recorrer `GridSearchCV`.\n",
    "- **cv=** la cantidad de folds para la estrategia de validación cruzada\n",
    "- **scoring=** cuál es la métrica que va a utiliza el método para evaluar cuál es la combinación de hiperparámetros más exitosa. \n",
    "\n",
    "Y uno opcional, pero que es muy recomendable ya que estas exploraciones exhaustivas pueden demorar mucho tiempo: \n",
    "- **n_jobs=** controla el número de procesadores que corren en paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos primero importando el método de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el estimador/modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la grilla de parámetros que queremos testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>HINT para no olvidar:</b> Recuerden que la grilla de parámetros tiene que ser un diccionario cuyas <b>claves</b> son el nombre de los hiperparámetros según está definido en la documentación, y los <b>valores</b> son la lista de valores que definimos de cada hiperparámetros y cuya combinación queremos explorar en nuestro modelo</code>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la cantidad de folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=StratifiedKFold(n_splits=10, random_state=19, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el método `GridSearchCV` eligiendo **accuracy** como medida de scoring dado que los datos están **balanceados**, y el resto de argumentos que definimos arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=folds, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos utilizando el método `.fit` de grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSeachCV` devuelve un dict con mucha información. Desde el tiempo de fiteo de cada parámetro hasta los scores promedio (vía validación cruzada). También provee los score en cada train y test set de la K-Fold Cross Validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En **cv_results_** podemos ver los detalles de cada uno de los hierparámetros o combinación de hiperparámeros que evaluó el `GridSeachCV`. Incluso podemos ver el score obtenido en cada split, el **mean_test_score** y el **std_test_score**.\n",
    "\n",
    "Además, encontramos el **rank_test_score** que nos indica cuál fue el hiperparámetro o combinación de hiperparámetros que obtuvo el mejor score de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.824436</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.049630</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.832211</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.839952</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.839986</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.841268</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.058499</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.842618</td>\n",
       "      <td>0.055652</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.850393</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.051204</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.842635</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>18</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.851743</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.840021</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.850461</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.850478</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>22</td>\n",
       "      <td>{'n_neighbors': 22}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.854340</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.846514</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>24</td>\n",
       "      <td>{'n_neighbors': 24}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.855622</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.852990</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.836124</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>28</td>\n",
       "      <td>{'n_neighbors': 28}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.838722</td>\n",
       "      <td>0.048770</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.841336</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.836124</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001564      0.000223         0.002488        0.000172   \n",
       "1        0.001461      0.000037         0.002459        0.000056   \n",
       "2        0.001434      0.000011         0.002480        0.000019   \n",
       "3        0.001431      0.000005         0.002499        0.000018   \n",
       "4        0.001458      0.000057         0.002579        0.000082   \n",
       "5        0.001549      0.000041         0.002724        0.000056   \n",
       "6        0.001539      0.000032         0.002748        0.000042   \n",
       "7        0.001546      0.000032         0.002750        0.000047   \n",
       "8        0.001539      0.000025         0.002788        0.000037   \n",
       "9        0.001557      0.000036         0.002811        0.000068   \n",
       "10       0.001540      0.000026         0.002826        0.000031   \n",
       "11       0.001565      0.000021         0.002859        0.000034   \n",
       "12       0.001619      0.000082         0.002920        0.000077   \n",
       "13       0.001465      0.000065         0.002694        0.000067   \n",
       "14       0.001435      0.000008         0.002690        0.000027   \n",
       "15       0.001432      0.000005         0.002697        0.000009   \n",
       "16       0.001440      0.000007         0.002714        0.000009   \n",
       "17       0.001437      0.000004         0.002734        0.000020   \n",
       "18       0.001440      0.000005         0.002741        0.000011   \n",
       "19       0.001440      0.000007         0.002752        0.000012   \n",
       "20       0.001442      0.000012         0.002771        0.000026   \n",
       "21       0.001435      0.000005         0.002786        0.000013   \n",
       "22       0.001431      0.000006         0.002798        0.000014   \n",
       "23       0.001435      0.000014         0.002815        0.000021   \n",
       "24       0.001436      0.000009         0.002820        0.000017   \n",
       "25       0.001435      0.000010         0.002841        0.000023   \n",
       "26       0.001436      0.000012         0.002847        0.000014   \n",
       "27       0.001435      0.000009         0.002857        0.000013   \n",
       "28       0.001440      0.000007         0.002891        0.000077   \n",
       "29       0.001460      0.000037         0.002910        0.000049   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}           0.779221   \n",
       "1                  2   {'n_neighbors': 2}           0.714286   \n",
       "2                  3   {'n_neighbors': 3}           0.831169   \n",
       "3                  4   {'n_neighbors': 4}           0.818182   \n",
       "4                  5   {'n_neighbors': 5}           0.779221   \n",
       "5                  6   {'n_neighbors': 6}           0.818182   \n",
       "6                  7   {'n_neighbors': 7}           0.818182   \n",
       "7                  8   {'n_neighbors': 8}           0.831169   \n",
       "8                  9   {'n_neighbors': 9}           0.818182   \n",
       "9                 10  {'n_neighbors': 10}           0.818182   \n",
       "10                11  {'n_neighbors': 11}           0.831169   \n",
       "11                12  {'n_neighbors': 12}           0.805195   \n",
       "12                13  {'n_neighbors': 13}           0.805195   \n",
       "13                14  {'n_neighbors': 14}           0.805195   \n",
       "14                15  {'n_neighbors': 15}           0.818182   \n",
       "15                16  {'n_neighbors': 16}           0.805195   \n",
       "16                17  {'n_neighbors': 17}           0.818182   \n",
       "17                18  {'n_neighbors': 18}           0.831169   \n",
       "18                19  {'n_neighbors': 19}           0.792208   \n",
       "19                20  {'n_neighbors': 20}           0.805195   \n",
       "20                21  {'n_neighbors': 21}           0.818182   \n",
       "21                22  {'n_neighbors': 22}           0.805195   \n",
       "22                23  {'n_neighbors': 23}           0.818182   \n",
       "23                24  {'n_neighbors': 24}           0.818182   \n",
       "24                25  {'n_neighbors': 25}           0.818182   \n",
       "25                26  {'n_neighbors': 26}           0.805195   \n",
       "26                27  {'n_neighbors': 27}           0.792208   \n",
       "27                28  {'n_neighbors': 28}           0.792208   \n",
       "28                29  {'n_neighbors': 29}           0.792208   \n",
       "29                30  {'n_neighbors': 30}           0.831169   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.818182           0.727273           0.792208   \n",
       "1            0.805195           0.714286           0.740260   \n",
       "2            0.805195           0.766234           0.818182   \n",
       "3            0.870130           0.779221           0.792208   \n",
       "4            0.870130           0.831169           0.818182   \n",
       "5            0.909091           0.844156           0.805195   \n",
       "6            0.883117           0.844156           0.818182   \n",
       "7            0.896104           0.844156           0.818182   \n",
       "8            0.909091           0.818182           0.818182   \n",
       "9            0.909091           0.831169           0.831169   \n",
       "10           0.922078           0.818182           0.857143   \n",
       "11           0.896104           0.831169           0.870130   \n",
       "12           0.896104           0.805195           0.870130   \n",
       "13           0.922078           0.818182           0.870130   \n",
       "14           0.935065           0.792208           0.883117   \n",
       "15           0.935065           0.844156           0.870130   \n",
       "16           0.922078           0.818182           0.844156   \n",
       "17           0.935065           0.844156           0.896104   \n",
       "18           0.922078           0.844156           0.857143   \n",
       "19           0.922078           0.857143           0.883117   \n",
       "20           0.909091           0.831169           0.883117   \n",
       "21           0.909091           0.870130           0.909091   \n",
       "22           0.896104           0.870130           0.896104   \n",
       "23           0.922078           0.844156           0.922078   \n",
       "24           0.909091           0.844156           0.870130   \n",
       "25           0.922078           0.844156           0.896104   \n",
       "26           0.909091           0.844156           0.857143   \n",
       "27           0.922078           0.844156           0.870130   \n",
       "28           0.922078           0.818182           0.883117   \n",
       "29           0.922078           0.805195           0.857143   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.831169           0.753247           0.779221   \n",
       "1            0.805195           0.740260           0.766234   \n",
       "2            0.909091           0.818182           0.805195   \n",
       "3            0.896104           0.818182           0.818182   \n",
       "4            0.935065           0.857143           0.818182   \n",
       "5            0.935065           0.883117           0.870130   \n",
       "6            0.922078           0.844156           0.870130   \n",
       "7            0.935065           0.844156           0.896104   \n",
       "8            0.909091           0.844156           0.909091   \n",
       "9            0.896104           0.870130           0.922078   \n",
       "10           0.896104           0.870130           0.896104   \n",
       "11           0.935065           0.883117           0.909091   \n",
       "12           0.922078           0.831169           0.922078   \n",
       "13           0.922078           0.870130           0.896104   \n",
       "14           0.909091           0.857143           0.922078   \n",
       "15           0.909091           0.844156           0.896104   \n",
       "16           0.883117           0.792208           0.896104   \n",
       "17           0.883117           0.805195           0.896104   \n",
       "18           0.870130           0.818182           0.896104   \n",
       "19           0.870130           0.831169           0.896104   \n",
       "20           0.883117           0.805195           0.896104   \n",
       "21           0.896104           0.805195           0.883117   \n",
       "22           0.896104           0.792208           0.883117   \n",
       "23           0.883117           0.818182           0.896104   \n",
       "24           0.909091           0.779221           0.896104   \n",
       "25           0.922078           0.805195           0.896104   \n",
       "26           0.909091           0.779221           0.896104   \n",
       "27           0.896104           0.792208           0.883117   \n",
       "28           0.870130           0.818182           0.883117   \n",
       "29           0.909091           0.792208           0.870130   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.714286           0.805195           0.697368         0.769737   \n",
       "1            0.766234           0.779221           0.736842         0.756801   \n",
       "2            0.792208           0.805195           0.881579         0.823223   \n",
       "3            0.753247           0.792208           0.828947         0.816661   \n",
       "4            0.727273           0.792208           0.815789         0.824436   \n",
       "5            0.766234           0.805195           0.828947         0.846531   \n",
       "6            0.727273           0.792208           0.802632         0.832211   \n",
       "7            0.766234           0.805195           0.763158         0.839952   \n",
       "8            0.792208           0.792208           0.789474         0.839986   \n",
       "9            0.779221           0.779221           0.776316         0.841268   \n",
       "10           0.779221           0.779221           0.789474         0.843882   \n",
       "11           0.740260           0.792208           0.802632         0.846497   \n",
       "12           0.740260           0.818182           0.815789         0.842618   \n",
       "13           0.779221           0.818182           0.802632         0.850393   \n",
       "14           0.753247           0.818182           0.815789         0.850410   \n",
       "15           0.753247           0.831169           0.815789         0.850410   \n",
       "16           0.779221           0.844156           0.828947         0.842635   \n",
       "17           0.766234           0.818182           0.842105         0.851743   \n",
       "18           0.779221           0.805195           0.815789         0.840021   \n",
       "19           0.766234           0.818182           0.855263         0.850461   \n",
       "20           0.779221           0.831169           0.868421         0.850478   \n",
       "21           0.792208           0.831169           0.842105         0.854340   \n",
       "22           0.766234           0.831169           0.815789         0.846514   \n",
       "23           0.805195           0.818182           0.828947         0.855622   \n",
       "24           0.805195           0.792208           0.828947         0.845232   \n",
       "25           0.844156           0.792208           0.802632         0.852990   \n",
       "26           0.805195           0.753247           0.815789         0.836124   \n",
       "27           0.792208           0.779221           0.815789         0.838722   \n",
       "28           0.792208           0.805195           0.828947         0.841336   \n",
       "29           0.792208           0.766234           0.815789         0.836124   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.042954               29  \n",
       "1         0.031504               30  \n",
       "2         0.040097               27  \n",
       "3         0.039934               28  \n",
       "4         0.053027               26  \n",
       "5         0.049630               10  \n",
       "6         0.051256               25  \n",
       "7         0.053365               21  \n",
       "8         0.047840               20  \n",
       "9         0.052560               18  \n",
       "10        0.049576               14  \n",
       "11        0.058499               12  \n",
       "12        0.055652               16  \n",
       "13        0.049609                9  \n",
       "14        0.057415                7  \n",
       "15        0.051204                8  \n",
       "16        0.043314               15  \n",
       "17        0.048001                4  \n",
       "18        0.043995               19  \n",
       "19        0.043921                6  \n",
       "20        0.041093                5  \n",
       "21        0.042655                2  \n",
       "22        0.045444               11  \n",
       "23        0.043381                1  \n",
       "24        0.045972               13  \n",
       "25        0.049213                3  \n",
       "26        0.053064               23  \n",
       "27        0.048770               22  \n",
       "28        0.042660               17  \n",
       "29        0.049444               23  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también acceder rápidamente a cuál fue el mejor modelo (ya que cuando tengamos muchos hiperparámetros no va a ser demasiado práctico ver la información de **cv_results_**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos ver todos los hiperparámetros del mejor modelo, donde se observa que el **número óptimo de vecinos** es 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855622009569378"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **best_score_** nos indica cuál fue la performance promedio del score de validación del grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 24}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finalmente **best_params_** nos muestra cuáles fueron los hiperparámetros seleccionados luego de la búsqueda exhaustiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/07_html.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El anterior fue un caso sencillo de búsqueda de hiperparámetros porque sólo optimizamos un hiperparámetro. Así que ahora que sabemos **\"HTML\"** probemos ahora, con el mismo caso, pero agregando **más hiperparámetros para tunear**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a agregar el **parámetro binario de Peso** del algoritmo **KNN** que determina si algunos vecinos tendrán mayor ponderación que otros a la hora de clasificar. El valor **distance** indica que el peso es inversamente proporcional a la distancia.\n",
    "\n",
    "[`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) exige que la **grilla de parámetros** a explorar venga en un diccionario con los **nombres de los parámetros** y la **lista de los posibles valores**. \n",
    "\n",
    "Noten que [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) tiene todos los métodos que la API de sklearn ofrece para modelos predictivos: fit, predict, predict_proba, etc. Es decir que una vez que tenemos el mejor modelo, podemos directamente usar el método predict de [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Algo que hace [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) es que una vez que elije el mejor o la mejor combinación de hiperparémetros, re-entrena el **estimador o modelo** utilizando esa combinación de hiperparámetros pero usando ahora **todos los datos de train**. Esto nos ahorra tener que entrenar nuevamente el modelo, y nos permite ir directamente a testearlo con los **datos de test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ahora el tunning se realizará iterando y alternando `weights` y `k` (nro. de vecinos cercanos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/ponete_a_prueba.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Entonces... </b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¿Cómo se realizará el proceso de búsqueda?:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9ba6d9884d417db68e414f78a23284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(width='100%'), options=('En forma exhaustiva', 'En forma aleatoria'), value='En for…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c899687bf14e2aaad3302070aedeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Validar', style=ButtonStyle(), tooltip='Click para validar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ffec1fd6714fd19f11b9176447e37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ejecutá esta celda...\n",
    "test_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos nuevamente el modelo como hicimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(knn, param_grid, cv=folds, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.823223</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.820608</td>\n",
       "      <td>0.040368</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.824436</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.830947</td>\n",
       "      <td>0.052598</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.049630</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.837406</td>\n",
       "      <td>0.045273</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.832211</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'uniform'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.839952</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>8</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 8, 'weights': 'distance'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.842567</td>\n",
       "      <td>0.062437</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.839986</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 9, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.841302</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.841268</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.845198</td>\n",
       "      <td>0.057225</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>11</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'uniform'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>11</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 11, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.843900</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>12</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.058499</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>12</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 12, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.843934</td>\n",
       "      <td>0.057550</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>13</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.842618</td>\n",
       "      <td>0.055652</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>13</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 13, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.842635</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>14</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.850393</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>14</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 14, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.058866</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>15</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 15, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.853025</td>\n",
       "      <td>0.051411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>16</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.051204</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 16, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>17</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.842635</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>17</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 17, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.847847</td>\n",
       "      <td>0.043891</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>18</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'uniform'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.851743</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>18</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 18, 'weights': 'distance'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.850444</td>\n",
       "      <td>0.044362</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>19</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'uniform'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.840021</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 19, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.847813</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.850461</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 20, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.039156</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>21</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.850478</td>\n",
       "      <td>0.041093</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>21</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 21, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.849163</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>22</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.854340</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>22</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 22, 'weights': 'distance'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.847847</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>23</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.846514</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>23</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 23, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>24</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.855622</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>24</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 24, 'weights': 'distance'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.858219</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'uniform'}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 25, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.041254</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>26</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'uniform'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.852990</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>26</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 26, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>27</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'uniform'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.836124</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>27</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 27, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.851692</td>\n",
       "      <td>0.046799</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>28</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'uniform'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.838722</td>\n",
       "      <td>0.048770</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>28</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 28, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>29</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'uniform'}</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.841336</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>29</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 29, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.043638</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'uniform'}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.836124</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 30, 'weights': 'distance'}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.841336</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001638      0.000304         0.002549        0.000232   \n",
       "1        0.001462      0.000029         0.001372        0.000053   \n",
       "2        0.001465      0.000039         0.002468        0.000030   \n",
       "3        0.001443      0.000018         0.001404        0.000024   \n",
       "4        0.001439      0.000015         0.002513        0.000062   \n",
       "5        0.001440      0.000016         0.001431        0.000032   \n",
       "6        0.001432      0.000007         0.002503        0.000013   \n",
       "7        0.001431      0.000008         0.001455        0.000030   \n",
       "8        0.001473      0.000059         0.002610        0.000099   \n",
       "9        0.001442      0.000007         0.001484        0.000016   \n",
       "10       0.001438      0.000007         0.002575        0.000032   \n",
       "11       0.001439      0.000008         0.001501        0.000013   \n",
       "12       0.001434      0.000005         0.002589        0.000025   \n",
       "13       0.001442      0.000005         0.001527        0.000014   \n",
       "14       0.001440      0.000006         0.002594        0.000014   \n",
       "15       0.001438      0.000006         0.001550        0.000032   \n",
       "16       0.001441      0.000004         0.002611        0.000015   \n",
       "17       0.001439      0.000010         0.001565        0.000016   \n",
       "18       0.001433      0.000006         0.002633        0.000028   \n",
       "19       0.001439      0.000010         0.001579        0.000015   \n",
       "20       0.001442      0.000008         0.002648        0.000010   \n",
       "21       0.001438      0.000009         0.001627        0.000061   \n",
       "22       0.001453      0.000022         0.002679        0.000017   \n",
       "23       0.001438      0.000007         0.001626        0.000010   \n",
       "24       0.001438      0.000006         0.002684        0.000024   \n",
       "25       0.001439      0.000008         0.001638        0.000006   \n",
       "26       0.001438      0.000012         0.002693        0.000023   \n",
       "27       0.001437      0.000007         0.001652        0.000013   \n",
       "28       0.001443      0.000011         0.002705        0.000017   \n",
       "29       0.001438      0.000005         0.001699        0.000094   \n",
       "30       0.001442      0.000013         0.002733        0.000040   \n",
       "31       0.001478      0.000080         0.001700        0.000037   \n",
       "32       0.001458      0.000045         0.005682        0.008813   \n",
       "33       0.001452      0.000024         0.001713        0.000028   \n",
       "34       0.001507      0.000064         0.002888        0.000122   \n",
       "35       0.001507      0.000076         0.001831        0.000103   \n",
       "36       0.001480      0.000039         0.002843        0.000096   \n",
       "37       0.001504      0.000087         0.001772        0.000047   \n",
       "38       0.001448      0.000020         0.002787        0.000039   \n",
       "39       0.001439      0.000008         0.001742        0.000014   \n",
       "40       0.001438      0.000010         0.002783        0.000025   \n",
       "41       0.001435      0.000007         0.001754        0.000011   \n",
       "42       0.001432      0.000011         0.002811        0.000038   \n",
       "43       0.001438      0.000007         0.001772        0.000016   \n",
       "44       0.001436      0.000007         0.002803        0.000019   \n",
       "45       0.001436      0.000005         0.001786        0.000011   \n",
       "46       0.001437      0.000006         0.002814        0.000013   \n",
       "47       0.001436      0.000010         0.001803        0.000017   \n",
       "48       0.001434      0.000009         0.002822        0.000016   \n",
       "49       0.001437      0.000007         0.001819        0.000022   \n",
       "50       0.001442      0.000009         0.002843        0.000015   \n",
       "51       0.001436      0.000006         0.001829        0.000021   \n",
       "52       0.001438      0.000007         0.002850        0.000015   \n",
       "53       0.001434      0.000008         0.001844        0.000026   \n",
       "54       0.001435      0.000005         0.002863        0.000015   \n",
       "55       0.001442      0.000018         0.001862        0.000024   \n",
       "56       0.001447      0.000028         0.002876        0.000016   \n",
       "57       0.001437      0.000007         0.001868        0.000010   \n",
       "58       0.001440      0.000011         0.002906        0.000048   \n",
       "59       0.001444      0.000020         0.001891        0.000014   \n",
       "\n",
       "   param_n_neighbors param_weights  \\\n",
       "0                  1       uniform   \n",
       "1                  1      distance   \n",
       "2                  2       uniform   \n",
       "3                  2      distance   \n",
       "4                  3       uniform   \n",
       "5                  3      distance   \n",
       "6                  4       uniform   \n",
       "7                  4      distance   \n",
       "8                  5       uniform   \n",
       "9                  5      distance   \n",
       "10                 6       uniform   \n",
       "11                 6      distance   \n",
       "12                 7       uniform   \n",
       "13                 7      distance   \n",
       "14                 8       uniform   \n",
       "15                 8      distance   \n",
       "16                 9       uniform   \n",
       "17                 9      distance   \n",
       "18                10       uniform   \n",
       "19                10      distance   \n",
       "20                11       uniform   \n",
       "21                11      distance   \n",
       "22                12       uniform   \n",
       "23                12      distance   \n",
       "24                13       uniform   \n",
       "25                13      distance   \n",
       "26                14       uniform   \n",
       "27                14      distance   \n",
       "28                15       uniform   \n",
       "29                15      distance   \n",
       "30                16       uniform   \n",
       "31                16      distance   \n",
       "32                17       uniform   \n",
       "33                17      distance   \n",
       "34                18       uniform   \n",
       "35                18      distance   \n",
       "36                19       uniform   \n",
       "37                19      distance   \n",
       "38                20       uniform   \n",
       "39                20      distance   \n",
       "40                21       uniform   \n",
       "41                21      distance   \n",
       "42                22       uniform   \n",
       "43                22      distance   \n",
       "44                23       uniform   \n",
       "45                23      distance   \n",
       "46                24       uniform   \n",
       "47                24      distance   \n",
       "48                25       uniform   \n",
       "49                25      distance   \n",
       "50                26       uniform   \n",
       "51                26      distance   \n",
       "52                27       uniform   \n",
       "53                27      distance   \n",
       "54                28       uniform   \n",
       "55                28      distance   \n",
       "56                29       uniform   \n",
       "57                29      distance   \n",
       "58                30       uniform   \n",
       "59                30      distance   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0     {'n_neighbors': 1, 'weights': 'uniform'}           0.779221   \n",
       "1    {'n_neighbors': 1, 'weights': 'distance'}           0.779221   \n",
       "2     {'n_neighbors': 2, 'weights': 'uniform'}           0.714286   \n",
       "3    {'n_neighbors': 2, 'weights': 'distance'}           0.779221   \n",
       "4     {'n_neighbors': 3, 'weights': 'uniform'}           0.831169   \n",
       "5    {'n_neighbors': 3, 'weights': 'distance'}           0.831169   \n",
       "6     {'n_neighbors': 4, 'weights': 'uniform'}           0.818182   \n",
       "7    {'n_neighbors': 4, 'weights': 'distance'}           0.818182   \n",
       "8     {'n_neighbors': 5, 'weights': 'uniform'}           0.779221   \n",
       "9    {'n_neighbors': 5, 'weights': 'distance'}           0.792208   \n",
       "10    {'n_neighbors': 6, 'weights': 'uniform'}           0.818182   \n",
       "11   {'n_neighbors': 6, 'weights': 'distance'}           0.844156   \n",
       "12    {'n_neighbors': 7, 'weights': 'uniform'}           0.818182   \n",
       "13   {'n_neighbors': 7, 'weights': 'distance'}           0.818182   \n",
       "14    {'n_neighbors': 8, 'weights': 'uniform'}           0.831169   \n",
       "15   {'n_neighbors': 8, 'weights': 'distance'}           0.831169   \n",
       "16    {'n_neighbors': 9, 'weights': 'uniform'}           0.818182   \n",
       "17   {'n_neighbors': 9, 'weights': 'distance'}           0.818182   \n",
       "18   {'n_neighbors': 10, 'weights': 'uniform'}           0.818182   \n",
       "19  {'n_neighbors': 10, 'weights': 'distance'}           0.818182   \n",
       "20   {'n_neighbors': 11, 'weights': 'uniform'}           0.831169   \n",
       "21  {'n_neighbors': 11, 'weights': 'distance'}           0.818182   \n",
       "22   {'n_neighbors': 12, 'weights': 'uniform'}           0.805195   \n",
       "23  {'n_neighbors': 12, 'weights': 'distance'}           0.818182   \n",
       "24   {'n_neighbors': 13, 'weights': 'uniform'}           0.805195   \n",
       "25  {'n_neighbors': 13, 'weights': 'distance'}           0.805195   \n",
       "26   {'n_neighbors': 14, 'weights': 'uniform'}           0.805195   \n",
       "27  {'n_neighbors': 14, 'weights': 'distance'}           0.805195   \n",
       "28   {'n_neighbors': 15, 'weights': 'uniform'}           0.818182   \n",
       "29  {'n_neighbors': 15, 'weights': 'distance'}           0.818182   \n",
       "30   {'n_neighbors': 16, 'weights': 'uniform'}           0.805195   \n",
       "31  {'n_neighbors': 16, 'weights': 'distance'}           0.818182   \n",
       "32   {'n_neighbors': 17, 'weights': 'uniform'}           0.818182   \n",
       "33  {'n_neighbors': 17, 'weights': 'distance'}           0.818182   \n",
       "34   {'n_neighbors': 18, 'weights': 'uniform'}           0.831169   \n",
       "35  {'n_neighbors': 18, 'weights': 'distance'}           0.831169   \n",
       "36   {'n_neighbors': 19, 'weights': 'uniform'}           0.792208   \n",
       "37  {'n_neighbors': 19, 'weights': 'distance'}           0.805195   \n",
       "38   {'n_neighbors': 20, 'weights': 'uniform'}           0.805195   \n",
       "39  {'n_neighbors': 20, 'weights': 'distance'}           0.818182   \n",
       "40   {'n_neighbors': 21, 'weights': 'uniform'}           0.818182   \n",
       "41  {'n_neighbors': 21, 'weights': 'distance'}           0.805195   \n",
       "42   {'n_neighbors': 22, 'weights': 'uniform'}           0.805195   \n",
       "43  {'n_neighbors': 22, 'weights': 'distance'}           0.792208   \n",
       "44   {'n_neighbors': 23, 'weights': 'uniform'}           0.818182   \n",
       "45  {'n_neighbors': 23, 'weights': 'distance'}           0.818182   \n",
       "46   {'n_neighbors': 24, 'weights': 'uniform'}           0.818182   \n",
       "47  {'n_neighbors': 24, 'weights': 'distance'}           0.818182   \n",
       "48   {'n_neighbors': 25, 'weights': 'uniform'}           0.818182   \n",
       "49  {'n_neighbors': 25, 'weights': 'distance'}           0.805195   \n",
       "50   {'n_neighbors': 26, 'weights': 'uniform'}           0.805195   \n",
       "51  {'n_neighbors': 26, 'weights': 'distance'}           0.805195   \n",
       "52   {'n_neighbors': 27, 'weights': 'uniform'}           0.792208   \n",
       "53  {'n_neighbors': 27, 'weights': 'distance'}           0.805195   \n",
       "54   {'n_neighbors': 28, 'weights': 'uniform'}           0.792208   \n",
       "55  {'n_neighbors': 28, 'weights': 'distance'}           0.805195   \n",
       "56   {'n_neighbors': 29, 'weights': 'uniform'}           0.792208   \n",
       "57  {'n_neighbors': 29, 'weights': 'distance'}           0.805195   \n",
       "58   {'n_neighbors': 30, 'weights': 'uniform'}           0.831169   \n",
       "59  {'n_neighbors': 30, 'weights': 'distance'}           0.805195   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.818182           0.727273           0.792208   \n",
       "1            0.818182           0.727273           0.792208   \n",
       "2            0.805195           0.714286           0.740260   \n",
       "3            0.818182           0.727273           0.792208   \n",
       "4            0.805195           0.766234           0.818182   \n",
       "5            0.805195           0.753247           0.818182   \n",
       "6            0.870130           0.779221           0.792208   \n",
       "7            0.857143           0.766234           0.805195   \n",
       "8            0.870130           0.831169           0.818182   \n",
       "9            0.883117           0.818182           0.818182   \n",
       "10           0.909091           0.844156           0.805195   \n",
       "11           0.870130           0.818182           0.818182   \n",
       "12           0.883117           0.844156           0.818182   \n",
       "13           0.883117           0.831169           0.818182   \n",
       "14           0.896104           0.844156           0.818182   \n",
       "15           0.922078           0.844156           0.805195   \n",
       "16           0.909091           0.818182           0.818182   \n",
       "17           0.922078           0.818182           0.818182   \n",
       "18           0.909091           0.831169           0.831169   \n",
       "19           0.922078           0.831169           0.818182   \n",
       "20           0.922078           0.818182           0.857143   \n",
       "21           0.922078           0.818182           0.844156   \n",
       "22           0.896104           0.831169           0.870130   \n",
       "23           0.909091           0.844156           0.844156   \n",
       "24           0.896104           0.805195           0.870130   \n",
       "25           0.896104           0.831169           0.857143   \n",
       "26           0.922078           0.818182           0.870130   \n",
       "27           0.909091           0.831169           0.857143   \n",
       "28           0.935065           0.792208           0.883117   \n",
       "29           0.922078           0.818182           0.870130   \n",
       "30           0.935065           0.844156           0.870130   \n",
       "31           0.909091           0.844156           0.883117   \n",
       "32           0.922078           0.818182           0.844156   \n",
       "33           0.922078           0.831169           0.870130   \n",
       "34           0.935065           0.844156           0.896104   \n",
       "35           0.922078           0.818182           0.883117   \n",
       "36           0.922078           0.844156           0.857143   \n",
       "37           0.922078           0.857143           0.883117   \n",
       "38           0.922078           0.857143           0.883117   \n",
       "39           0.909091           0.844156           0.870130   \n",
       "40           0.909091           0.831169           0.883117   \n",
       "41           0.909091           0.844156           0.883117   \n",
       "42           0.909091           0.870130           0.909091   \n",
       "43           0.909091           0.857143           0.896104   \n",
       "44           0.896104           0.870130           0.896104   \n",
       "45           0.896104           0.857143           0.883117   \n",
       "46           0.922078           0.844156           0.922078   \n",
       "47           0.909091           0.870130           0.896104   \n",
       "48           0.909091           0.844156           0.870130   \n",
       "49           0.896104           0.844156           0.883117   \n",
       "50           0.922078           0.844156           0.896104   \n",
       "51           0.909091           0.870130           0.883117   \n",
       "52           0.909091           0.844156           0.857143   \n",
       "53           0.896104           0.844156           0.909091   \n",
       "54           0.922078           0.844156           0.870130   \n",
       "55           0.909091           0.844156           0.883117   \n",
       "56           0.922078           0.818182           0.883117   \n",
       "57           0.909091           0.831169           0.896104   \n",
       "58           0.922078           0.805195           0.857143   \n",
       "59           0.909091           0.805195           0.870130   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.831169           0.753247           0.779221   \n",
       "1            0.831169           0.753247           0.779221   \n",
       "2            0.805195           0.740260           0.766234   \n",
       "3            0.831169           0.753247           0.779221   \n",
       "4            0.909091           0.818182           0.805195   \n",
       "5            0.909091           0.818182           0.805195   \n",
       "6            0.896104           0.818182           0.818182   \n",
       "7            0.909091           0.831169           0.857143   \n",
       "8            0.935065           0.857143           0.818182   \n",
       "9            0.935065           0.857143           0.844156   \n",
       "10           0.935065           0.883117           0.870130   \n",
       "11           0.922078           0.870130           0.870130   \n",
       "12           0.922078           0.844156           0.870130   \n",
       "13           0.935065           0.844156           0.909091   \n",
       "14           0.935065           0.844156           0.896104   \n",
       "15           0.935065           0.844156           0.922078   \n",
       "16           0.909091           0.844156           0.909091   \n",
       "17           0.909091           0.844156           0.922078   \n",
       "18           0.896104           0.870130           0.922078   \n",
       "19           0.909091           0.870130           0.935065   \n",
       "20           0.896104           0.870130           0.896104   \n",
       "21           0.883117           0.870130           0.909091   \n",
       "22           0.935065           0.883117           0.909091   \n",
       "23           0.935065           0.857143           0.896104   \n",
       "24           0.922078           0.831169           0.922078   \n",
       "25           0.909091           0.844156           0.909091   \n",
       "26           0.922078           0.870130           0.896104   \n",
       "27           0.935065           0.883117           0.922078   \n",
       "28           0.909091           0.857143           0.922078   \n",
       "29           0.909091           0.857143           0.922078   \n",
       "30           0.909091           0.844156           0.896104   \n",
       "31           0.896104           0.870130           0.883117   \n",
       "32           0.883117           0.792208           0.896104   \n",
       "33           0.870130           0.831169           0.896104   \n",
       "34           0.883117           0.805195           0.896104   \n",
       "35           0.870130           0.844156           0.896104   \n",
       "36           0.870130           0.818182           0.896104   \n",
       "37           0.870130           0.844156           0.909091   \n",
       "38           0.870130           0.831169           0.896104   \n",
       "39           0.870130           0.857143           0.896104   \n",
       "40           0.883117           0.805195           0.896104   \n",
       "41           0.870130           0.831169           0.922078   \n",
       "42           0.896104           0.805195           0.883117   \n",
       "43           0.896104           0.805195           0.883117   \n",
       "44           0.896104           0.792208           0.883117   \n",
       "45           0.883117           0.818182           0.883117   \n",
       "46           0.883117           0.818182           0.896104   \n",
       "47           0.883117           0.818182           0.909091   \n",
       "48           0.909091           0.779221           0.896104   \n",
       "49           0.896104           0.805195           0.896104   \n",
       "50           0.922078           0.805195           0.896104   \n",
       "51           0.909091           0.805195           0.909091   \n",
       "52           0.909091           0.779221           0.896104   \n",
       "53           0.922078           0.818182           0.896104   \n",
       "54           0.896104           0.792208           0.883117   \n",
       "55           0.883117           0.818182           0.896104   \n",
       "56           0.870130           0.818182           0.883117   \n",
       "57           0.883117           0.831169           0.896104   \n",
       "58           0.909091           0.792208           0.870130   \n",
       "59           0.896104           0.818182           0.870130   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.714286           0.805195           0.697368         0.769737   \n",
       "1            0.714286           0.805195           0.697368         0.769737   \n",
       "2            0.766234           0.779221           0.736842         0.756801   \n",
       "3            0.714286           0.805195           0.697368         0.769737   \n",
       "4            0.792208           0.805195           0.881579         0.823223   \n",
       "5            0.792208           0.805195           0.868421         0.820608   \n",
       "6            0.753247           0.792208           0.828947         0.816661   \n",
       "7            0.766234           0.818182           0.842105         0.827068   \n",
       "8            0.727273           0.792208           0.815789         0.824436   \n",
       "9            0.727273           0.805195           0.828947         0.830947   \n",
       "10           0.766234           0.805195           0.828947         0.846531   \n",
       "11           0.753247           0.805195           0.802632         0.837406   \n",
       "12           0.727273           0.792208           0.802632         0.832211   \n",
       "13           0.727273           0.792208           0.815789         0.837423   \n",
       "14           0.766234           0.805195           0.763158         0.839952   \n",
       "15           0.740260           0.805195           0.776316         0.842567   \n",
       "16           0.792208           0.792208           0.789474         0.839986   \n",
       "17           0.779221           0.779221           0.802632         0.841302   \n",
       "18           0.779221           0.779221           0.776316         0.841268   \n",
       "19           0.766234           0.779221           0.802632         0.845198   \n",
       "20           0.779221           0.779221           0.789474         0.843882   \n",
       "21           0.766234           0.805195           0.802632         0.843900   \n",
       "22           0.740260           0.792208           0.802632         0.846497   \n",
       "23           0.740260           0.766234           0.828947         0.843934   \n",
       "24           0.740260           0.818182           0.815789         0.842618   \n",
       "25           0.727273           0.818182           0.828947         0.842635   \n",
       "26           0.779221           0.818182           0.802632         0.850393   \n",
       "27           0.740260           0.805195           0.815789         0.850410   \n",
       "28           0.753247           0.818182           0.815789         0.850410   \n",
       "29           0.753247           0.831169           0.828947         0.853025   \n",
       "30           0.753247           0.831169           0.815789         0.850410   \n",
       "31           0.740260           0.831169           0.828947         0.850427   \n",
       "32           0.779221           0.844156           0.828947         0.842635   \n",
       "33           0.753247           0.844156           0.842105         0.847847   \n",
       "34           0.766234           0.818182           0.842105         0.851743   \n",
       "35           0.753247           0.844156           0.842105         0.850444   \n",
       "36           0.779221           0.805195           0.815789         0.840021   \n",
       "37           0.740260           0.831169           0.815789         0.847813   \n",
       "38           0.766234           0.818182           0.855263         0.850461   \n",
       "39           0.766234           0.831169           0.828947         0.849129   \n",
       "40           0.779221           0.831169           0.868421         0.850478   \n",
       "41           0.740260           0.831169           0.855263         0.849163   \n",
       "42           0.792208           0.831169           0.842105         0.854340   \n",
       "43           0.766234           0.831169           0.842105         0.847847   \n",
       "44           0.766234           0.831169           0.815789         0.846514   \n",
       "45           0.753247           0.844156           0.815789         0.845215   \n",
       "46           0.805195           0.818182           0.828947         0.855622   \n",
       "47           0.805195           0.844156           0.828947         0.858219   \n",
       "48           0.805195           0.792208           0.828947         0.845232   \n",
       "49           0.779221           0.857143           0.828947         0.849129   \n",
       "50           0.844156           0.792208           0.802632         0.852990   \n",
       "51           0.805195           0.831169           0.815789         0.854306   \n",
       "52           0.805195           0.753247           0.815789         0.836124   \n",
       "53           0.792208           0.831169           0.802632         0.851692   \n",
       "54           0.792208           0.779221           0.815789         0.838722   \n",
       "55           0.792208           0.805195           0.828947         0.846531   \n",
       "56           0.792208           0.805195           0.828947         0.841336   \n",
       "57           0.766234           0.844156           0.828947         0.849129   \n",
       "58           0.792208           0.766234           0.815789         0.836124   \n",
       "59           0.766234           0.844156           0.828947         0.841336   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.042954               57  \n",
       "1         0.042954               57  \n",
       "2         0.031504               60  \n",
       "3         0.042954               57  \n",
       "4         0.040097               54  \n",
       "5         0.040368               55  \n",
       "6         0.039934               56  \n",
       "7         0.041009               52  \n",
       "8         0.053027               53  \n",
       "9         0.052598               51  \n",
       "10        0.049630               25  \n",
       "11        0.045273               47  \n",
       "12        0.051256               50  \n",
       "13        0.056770               46  \n",
       "14        0.053365               44  \n",
       "15        0.062437               37  \n",
       "16        0.047840               43  \n",
       "17        0.053348               40  \n",
       "18        0.052560               41  \n",
       "19        0.057225               30  \n",
       "20        0.049576               33  \n",
       "21        0.048108               32  \n",
       "22        0.058499               27  \n",
       "23        0.057550               31  \n",
       "24        0.055652               36  \n",
       "25        0.052470               34  \n",
       "26        0.049609               16  \n",
       "27        0.058866               14  \n",
       "28        0.057415               13  \n",
       "29        0.051411                5  \n",
       "30        0.051204               14  \n",
       "31        0.047012               12  \n",
       "32        0.043314               34  \n",
       "33        0.043891               21  \n",
       "34        0.048001                7  \n",
       "35        0.044362               11  \n",
       "36        0.043995               42  \n",
       "37        0.050795               23  \n",
       "38        0.043921               10  \n",
       "39        0.039156               18  \n",
       "40        0.041093                9  \n",
       "41        0.050003               17  \n",
       "42        0.042655                3  \n",
       "43        0.046503               21  \n",
       "44        0.045444               26  \n",
       "45        0.042224               29  \n",
       "46        0.043381                2  \n",
       "47        0.038007                1  \n",
       "48        0.045972               28  \n",
       "49        0.041254               20  \n",
       "50        0.049213                6  \n",
       "51        0.043976                4  \n",
       "52        0.053064               48  \n",
       "53        0.046799                8  \n",
       "54        0.048770               45  \n",
       "55        0.040663               24  \n",
       "56        0.042660               38  \n",
       "57        0.043638               18  \n",
       "58        0.049444               48  \n",
       "59        0.042660               38  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(¡Fijense que ahora la grilla de resulados es mucho más larga!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál habrá sido el **mejor modelo**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=24, weights='distance')\n",
      "0.8582194121667805\n",
      "{'n_neighbors': 24, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta nueva búsqueda de **hiperparámetros**, los mejores resultados los obtuvimos con k=25 y con **distance**. Si vemos el resultado obtenido en la primer búsqueda (0.8556566970091027), en esta obtuvimos un resultado apenas por arriba = 0.8582574772431729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>HINT para no olvidar:</b> Si estuviésemos enfrentando un problema de clases desbalanceadas, o nos interesaría ajustar los hiperparámetros en función de otra métrica de evaluación, recuerden que pueden hacerlo cambiando el parámetro scoring de <code>GridSearchCV</code> por otras medidas como <b>recall</b>, <b>f1</b> o <b>precision.</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Llego el momento de la verdad...**\n",
    "<img src=\"img/08_la_verdad.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos los mejores **hiperparámetros** para estimar las predicciones sobre los **datos de test** y evaluar cómo generaliza nuestro modelo ante datos con los que no fue entrenado y que no fueron usados para la **búsqueda de hiperparámetros**.\n",
    "\n",
    "Para ello, podemos usar el atajo que tiene `GridSeachCV`: usando el método `predict` sobre objeto `grid` (que ya está entrenado con todos los **datos de train** y con la mejor combinación de hiperparámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos importar de **sklearn**, [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) que nos va a brindar un reporte completo de las principales **métricas de evaluación** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.88      0.87      0.88        61\n",
      "        bajo       0.93      0.91      0.92        55\n",
      "       medio       0.84      0.86      0.85        77\n",
      "\n",
      "    accuracy                           0.88       193\n",
      "   macro avg       0.88      0.88      0.88       193\n",
      "weighted avg       0.88      0.88      0.88       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varias cosas sobre este reporte: \n",
    "- Tenemos los resulados de varias mérricas de evaluación que ya son viejas conocidas nuestras como **precision**, **recall**, **f1-score** y **accuracy**\n",
    "- El **accuracy** general (que se refiere a nuestra capacidad de identificar bien los **TP** y **TN** de cada clase es 0.88, se encuentra en la fila que dice **accuracy** y (aunque parezca contra-intuitivo) debajo de **f1-score**.\n",
    "- Después, para cada nivel tenemos **precision**, **recall** y **f1-score**. Esto nos indica qué tan bien pudimos identificar cada una de estas etiquetas. Si nos detenemos en el **f1-score** vemos que la etiqueta **bajo** es aquella que pudimos identificar con mayor sensibilidad y precisión. \n",
    "- Por otro lado, la columna **support** tiene el número de casos positivos por cada etiqueta de los datos de test (61 para alto, 55 para bajo y 77 para medio). Y 193 es la cantidad total sumada de casos positivos de las tres etiquetas.\n",
    "- Pero, **¿qué significa `macro avg` y `weighted avg`?**:\n",
    "    - `macro avg` es la media de cada métrica de evaluación de las tres etiquetas. Si tuviésemos que reportar la **presicion** promedio de nuestros resultados, sería 0.89 que es el promedio entre la **precision** que obtuvimos para cada clase (0.90, 0.93, 0.84). Lo que hay que tener en cuenta es que siempre es recomendable ver cómo nos fue con cada clase y no confiar demasiado en los valores medios (en particular si por nuestro problema de negocios nos interesa más una clase que otra, o si estás lidiando con clases desbalanceadas).\n",
    "    - `weighted avg` es lo mismo que el anterior, pero se calcula la media ponderada por **support**, es decir, teniendo en cuenta la cantidad de casos de cada clase. Este promedio toma en cuenta el potencial **desbalanceo de clases** y puede ser muy útil ante esos escenarios. Fijense que, en este caso, dado que las clases no están desbalanceadas en forma grosera, ambas medidas son casi idénticas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora cómo se ve la **matriz de confusión**:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0  8]\n",
      " [ 0 50  5]\n",
      " [ 7  4 66]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred_grid)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fijense que como en la matriz de confusión no definimos ningún orden, la primera fila corresponde a los casos reales de la etiqueta **alto**, la segunda a **bajo** y la tercera a **medio**. Y en el caso de las columnas de las predicciones ocurre lo mismo: la primera columna corresponde a las predicciones de **alto**, la segunda a **bajo** y la tercera a **medio**.\n",
    "- Podemos ver claramente que la etiqueta **medio** es la que más confunde el modelo; esto tiene mucho sentido ya que los extremos son fáciles de separar más no así los casos que están en el medio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>    \n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Cómo le fue finalmente a nuestro modelo para identificar los jugadores según su nivel de performance? ¿Qué te parecen los resultados que obtuvimos?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.4\"></a>\n",
    "### 2.4 Usando [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos ahora usar [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Recuerden que la diferencia es que con este método no vamos a explorar **todo el espacio** de **hiperparámetros** sino que se van a explorar combinaciones al azar. Aunque esta estrategia no cubre todo el espacio, puede tener sus ventajas cuando trabajamos con datasets muy pesados o cuando tenemos espacios de hiperparámetros muy grandes (como nos va a pasar con los modelos más avanzados que veamos al final de curso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros de [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) son los mismos que los de `GridSearchCV` pero se agrega `n_iter` que nos va a indicar qué número de combinaciones de hiperparámetros queremos seleccionar al azar de la grilla que definimos. Por default está seteado en **10** así que podríamos aumentarlo para incrementar nuestras chances de encontrar combinaciones óptimas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos nuevamente nuestra **grilla de hiperparámetros**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el tunning se realizará con combinaciones aleatorias de `weights` y `k` (nro. de vecinos cercanos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=19, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(), n_iter=20,\n",
       "                   param_distributions={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29, 30],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   random_state=10, scoring='accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = RandomizedSearchCV(knn, param_grid, n_iter=20, cv=folds, scoring='accuracy',random_state=10)\n",
    "random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mismos métodos que teníamos con `GridSearchCV` los tenemos acá: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>distance</td>\n",
       "      <td>16</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 16}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 2}</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>uniform</td>\n",
       "      <td>20</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 20}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.850461</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>distance</td>\n",
       "      <td>14</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 14}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.850410</td>\n",
       "      <td>0.058866</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>distance</td>\n",
       "      <td>11</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 11}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.843900</td>\n",
       "      <td>0.048108</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>distance</td>\n",
       "      <td>9</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 9}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.841302</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>uniform</td>\n",
       "      <td>24</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 24}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.855622</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 2}</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>distance</td>\n",
       "      <td>12</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 12}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.843934</td>\n",
       "      <td>0.057550</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>uniform</td>\n",
       "      <td>14</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 14}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.850393</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>distance</td>\n",
       "      <td>18</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 18}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.850444</td>\n",
       "      <td>0.044362</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>distance</td>\n",
       "      <td>20</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 20}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.039156</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>uniform</td>\n",
       "      <td>11</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 11}</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>distance</td>\n",
       "      <td>19</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 19}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.847813</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>distance</td>\n",
       "      <td>4</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 4}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 4}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>distance</td>\n",
       "      <td>23</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 23}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>distance</td>\n",
       "      <td>29</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 29}</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.043638</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>distance</td>\n",
       "      <td>24</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 24}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.858219</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>uniform</td>\n",
       "      <td>6</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 6}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.049630</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001923      0.000254         0.002194        0.000334   \n",
       "1        0.001491      0.000049         0.001462        0.000110   \n",
       "2        0.001482      0.000054         0.002910        0.000150   \n",
       "3        0.001513      0.000086         0.001746        0.000150   \n",
       "4        0.001495      0.000064         0.001685        0.000138   \n",
       "5        0.001465      0.000044         0.001582        0.000036   \n",
       "6        0.001447      0.000005         0.002825        0.000018   \n",
       "7        0.001435      0.000010         0.002439        0.000012   \n",
       "8        0.001440      0.000008         0.001619        0.000025   \n",
       "9        0.001439      0.000007         0.002691        0.000016   \n",
       "10       0.001459      0.000051         0.001724        0.000065   \n",
       "11       0.001461      0.000020         0.001758        0.000044   \n",
       "12       0.001438      0.000006         0.002645        0.000019   \n",
       "13       0.001442      0.000011         0.001722        0.000016   \n",
       "14       0.001434      0.000008         0.001455        0.000037   \n",
       "15       0.001434      0.000008         0.002508        0.000012   \n",
       "16       0.001445      0.000011         0.001784        0.000024   \n",
       "17       0.001446      0.000008         0.001866        0.000014   \n",
       "18       0.001443      0.000007         0.001790        0.000009   \n",
       "19       0.001435      0.000008         0.002563        0.000035   \n",
       "\n",
       "   param_weights param_n_neighbors  \\\n",
       "0       distance                16   \n",
       "1       distance                 2   \n",
       "2        uniform                20   \n",
       "3       distance                14   \n",
       "4       distance                11   \n",
       "5       distance                 9   \n",
       "6        uniform                24   \n",
       "7        uniform                 2   \n",
       "8       distance                12   \n",
       "9        uniform                14   \n",
       "10      distance                18   \n",
       "11      distance                20   \n",
       "12       uniform                11   \n",
       "13      distance                19   \n",
       "14      distance                 4   \n",
       "15       uniform                 4   \n",
       "16      distance                23   \n",
       "17      distance                29   \n",
       "18      distance                24   \n",
       "19       uniform                 6   \n",
       "\n",
       "                                        params  split0_test_score  \\\n",
       "0   {'weights': 'distance', 'n_neighbors': 16}           0.818182   \n",
       "1    {'weights': 'distance', 'n_neighbors': 2}           0.779221   \n",
       "2    {'weights': 'uniform', 'n_neighbors': 20}           0.805195   \n",
       "3   {'weights': 'distance', 'n_neighbors': 14}           0.805195   \n",
       "4   {'weights': 'distance', 'n_neighbors': 11}           0.818182   \n",
       "5    {'weights': 'distance', 'n_neighbors': 9}           0.818182   \n",
       "6    {'weights': 'uniform', 'n_neighbors': 24}           0.818182   \n",
       "7     {'weights': 'uniform', 'n_neighbors': 2}           0.714286   \n",
       "8   {'weights': 'distance', 'n_neighbors': 12}           0.818182   \n",
       "9    {'weights': 'uniform', 'n_neighbors': 14}           0.805195   \n",
       "10  {'weights': 'distance', 'n_neighbors': 18}           0.831169   \n",
       "11  {'weights': 'distance', 'n_neighbors': 20}           0.818182   \n",
       "12   {'weights': 'uniform', 'n_neighbors': 11}           0.831169   \n",
       "13  {'weights': 'distance', 'n_neighbors': 19}           0.805195   \n",
       "14   {'weights': 'distance', 'n_neighbors': 4}           0.818182   \n",
       "15    {'weights': 'uniform', 'n_neighbors': 4}           0.818182   \n",
       "16  {'weights': 'distance', 'n_neighbors': 23}           0.818182   \n",
       "17  {'weights': 'distance', 'n_neighbors': 29}           0.805195   \n",
       "18  {'weights': 'distance', 'n_neighbors': 24}           0.818182   \n",
       "19    {'weights': 'uniform', 'n_neighbors': 6}           0.818182   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.909091           0.844156           0.883117   \n",
       "1            0.818182           0.727273           0.792208   \n",
       "2            0.922078           0.857143           0.883117   \n",
       "3            0.909091           0.831169           0.857143   \n",
       "4            0.922078           0.818182           0.844156   \n",
       "5            0.922078           0.818182           0.818182   \n",
       "6            0.922078           0.844156           0.922078   \n",
       "7            0.805195           0.714286           0.740260   \n",
       "8            0.909091           0.844156           0.844156   \n",
       "9            0.922078           0.818182           0.870130   \n",
       "10           0.922078           0.818182           0.883117   \n",
       "11           0.909091           0.844156           0.870130   \n",
       "12           0.922078           0.818182           0.857143   \n",
       "13           0.922078           0.857143           0.883117   \n",
       "14           0.857143           0.766234           0.805195   \n",
       "15           0.870130           0.779221           0.792208   \n",
       "16           0.896104           0.857143           0.883117   \n",
       "17           0.909091           0.831169           0.896104   \n",
       "18           0.909091           0.870130           0.896104   \n",
       "19           0.909091           0.844156           0.805195   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.896104           0.870130           0.883117   \n",
       "1            0.831169           0.753247           0.779221   \n",
       "2            0.870130           0.831169           0.896104   \n",
       "3            0.935065           0.883117           0.922078   \n",
       "4            0.883117           0.870130           0.909091   \n",
       "5            0.909091           0.844156           0.922078   \n",
       "6            0.883117           0.818182           0.896104   \n",
       "7            0.805195           0.740260           0.766234   \n",
       "8            0.935065           0.857143           0.896104   \n",
       "9            0.922078           0.870130           0.896104   \n",
       "10           0.870130           0.844156           0.896104   \n",
       "11           0.870130           0.857143           0.896104   \n",
       "12           0.896104           0.870130           0.896104   \n",
       "13           0.870130           0.844156           0.909091   \n",
       "14           0.909091           0.831169           0.857143   \n",
       "15           0.896104           0.818182           0.818182   \n",
       "16           0.883117           0.818182           0.883117   \n",
       "17           0.883117           0.831169           0.896104   \n",
       "18           0.883117           0.818182           0.909091   \n",
       "19           0.935065           0.883117           0.870130   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.740260           0.831169           0.828947         0.850427   \n",
       "1            0.714286           0.805195           0.697368         0.769737   \n",
       "2            0.766234           0.818182           0.855263         0.850461   \n",
       "3            0.740260           0.805195           0.815789         0.850410   \n",
       "4            0.766234           0.805195           0.802632         0.843900   \n",
       "5            0.779221           0.779221           0.802632         0.841302   \n",
       "6            0.805195           0.818182           0.828947         0.855622   \n",
       "7            0.766234           0.779221           0.736842         0.756801   \n",
       "8            0.740260           0.766234           0.828947         0.843934   \n",
       "9            0.779221           0.818182           0.802632         0.850393   \n",
       "10           0.753247           0.844156           0.842105         0.850444   \n",
       "11           0.766234           0.831169           0.828947         0.849129   \n",
       "12           0.779221           0.779221           0.789474         0.843882   \n",
       "13           0.740260           0.831169           0.815789         0.847813   \n",
       "14           0.766234           0.818182           0.842105         0.827068   \n",
       "15           0.753247           0.792208           0.828947         0.816661   \n",
       "16           0.753247           0.844156           0.815789         0.845215   \n",
       "17           0.766234           0.844156           0.828947         0.849129   \n",
       "18           0.805195           0.844156           0.828947         0.858219   \n",
       "19           0.766234           0.805195           0.828947         0.846531   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.047012                5  \n",
       "1         0.042954               19  \n",
       "2         0.043921                3  \n",
       "3         0.058866                6  \n",
       "4         0.048108               14  \n",
       "5         0.053348               16  \n",
       "6         0.043381                2  \n",
       "7         0.031504               20  \n",
       "8         0.057550               13  \n",
       "9         0.049609                7  \n",
       "10        0.044362                4  \n",
       "11        0.039156                8  \n",
       "12        0.049576               15  \n",
       "13        0.050795               10  \n",
       "14        0.041009               17  \n",
       "15        0.039934               18  \n",
       "16        0.042224               12  \n",
       "17        0.043638                8  \n",
       "18        0.038007                1  \n",
       "19        0.049630               11  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=24, weights='distance')\n",
      "0.8582194121667805\n",
      "{'weights': 'distance', 'n_neighbors': 24}\n"
     ]
    }
   ],
   "source": [
    "print (random.best_estimator_)\n",
    "print(random.best_score_)\n",
    "print(random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que `RandomizedSearchCV` no obtuvo el mismo resultado que `GridSearchCV`, simplemente porque no probó tantas combinaciones y no encontró la óptima. Aunque fijense que el score de validación es muy similar al que obtuvimos antes, y acá ahorramos tiempo de cómputo.\n",
    "\n",
    "Incluso podemos utilizar el método **predict** con el mejor modelo ya entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.88      0.87      0.88        61\n",
      "        bajo       0.93      0.91      0.92        55\n",
      "       medio       0.84      0.86      0.85        77\n",
      "\n",
      "    accuracy                           0.88       193\n",
      "   macro avg       0.88      0.88      0.88       193\n",
      "weighted avg       0.88      0.88      0.88       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0  8]\n",
      " [ 0 50  5]\n",
      " [ 7  4 66]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, random.predict(X_test))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Y con los **datos de test** obtuvimos **casi** los mismos resultados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#tabla_contenidos'>Volver a TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.\"></a> \n",
    "## 3. Comentarios finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/23_conclusion.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja7\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/en_resumen.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>  \n",
    "  <div style=\"float:left;width: 85%;\"><label><b>En conclusión...</b></label></div>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- Los **hiperparámetros** son aquella/s característica/s externas de un modelo que no se \"aprenden\" de forma directa a partir del entrenamiento con los datos, sino que tienen que definirse con anterioridad.\n",
    "\n",
    "\n",
    "- Los **parámetros** de un modelo son características o propiedades internas cuyos valores son estimados a partir del entrenamiento con los datos.\n",
    "\n",
    "\n",
    "- Los **hiperparámetros** son muy importantes a la hora de entrenar un modelo ya que van a impactar en su desempeño y no se puede saber **a priori** cuáles son los mejores\n",
    "\n",
    "\n",
    "- Existen dos grandes métodos o procesos (aunque no son los únicos) que nos permiten buscar cuáles son los mejores **hiperparámetros** (**hyper-parameter tunning**): [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) y [`RandomSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "\n",
    "- [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) se caracteriza por hacer una búsqueda **exhaustiva para cada valor de la grilla de hiperparámetros** y elige la combinación de ellos que minimizan una determinada métrica de error.\n",
    "\n",
    "- [`RandomizedSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) realiza la búsqueda de la mejor combinación de **hiperparámetros** pero a partir de seleccionar en forma **aleatoria** un **subset** de los **hiperparámetros**, lo que achica el espacio de búsqueda y reduce el tiempo de cómputo.\n",
    "\n",
    "\n",
    "- La receta general para la búsqueda de **hiperparámetros** consta de: \n",
    "    - Elegir un **estimador (modelo)**\n",
    "    - Elegir un **espacio de hiperparámetros**\n",
    "    - Elegir un **método de búsqueda** (`RandomSearch`,`GridSearch`).\n",
    "    - Definir un **esquema de validación cruzada**\n",
    "    - Definir una **métrica de evaluación**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#tabla_contenidos'>Volver a TOC</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
