{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ca092ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/csuarezgurruchaga/Desktop/Digital-House/CLASE_23/dsad_2021/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "Running command `conda install --yes nltk=3.5.0`... ok\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89fbd8",
   "metadata": {},
   "source": [
    "[<img src=\"https://www.digitalhouse.com/ar/logo-DH.png\" width=\"400\" height=\"200\" align='right'>](http://digitalhouse.com.ar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6ff5d",
   "metadata": {},
   "source": [
    "# Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503a67e",
   "metadata": {},
   "source": [
    "### Nota:\n",
    "\n",
    "En este ejercicio vamos a escalar las features del dataset usando `MinMaxScaler` con el objetivo de que tengan un ejercicio resuelto de ejemplo con una alternativa a `StandardScaler`, no porque consideremos que en este problema `MinMaxScaler` resulte en una mejor performance que `StandardScaler`.\n",
    "\n",
    "---\n",
    "\n",
    "Aunque la normalización a través de min-max es una técnica de uso común que es útil cuando necesitamos valores en un intervalo acotado, la estandarización puede ser más práctica para muchos algoritmos de aprendizaje automático. \n",
    "\n",
    "La razón es que muchos modelos lineales inicializan las ponderaciones en O o valores aleatorios pequeños cercanos a 0.\n",
    "\n",
    "Usando la estandarización centramos las columnas de features en la media 0 con el desvío estándar 1, así las columnas de features adoptan la forma de una distribución normal, lo que facilita el aprendizaje de los pesos. \n",
    "\n",
    "Además, la estandarización mantiene información útil sobre los valores atípicos y hace que el algoritmo sea menos sensible a ellos en contraste con el escalado min-max, que escala los datos a un rango limitado de valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faefb47",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53fb458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import eval_measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956cfe0",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Este dataset contiene los precios y otros atributos de casi 54.000 diamantes.\n",
    "\n",
    "Sus features son:\n",
    "\n",
    "* **price**: price in US dollars (\\$326--\\$18,823).  **Esta es la variable target**.\n",
    "\n",
    "* carat: weight of the diamond (0.2--5.01)\n",
    "\n",
    "* cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "\n",
    "* color: diamond colour, from J (worst) to D (best)\n",
    "\n",
    "* clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "\n",
    "* x: length in mm (0--10.74)\n",
    "\n",
    "* y: width in mm (0--58.9)\n",
    "\n",
    "* z: depth in mm (0--31.8)\n",
    "\n",
    "* depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "\n",
    "* table: width of top of diamond relative to widest point (43--95)\n",
    "\n",
    "Fuente: https://www.kaggle.com/shivam2503/diamonds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7abe10",
   "metadata": {},
   "source": [
    "## Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35b5a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/diamonds.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b0c606a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad7229",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Normalicemos las features y creemos las variables dummies necesarias para poder entrenar un modelo de regresión para predecir el valor de `price` para cada registro\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4170a100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<53940x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 152694 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para las variables categoricas, tengo que hacer OneHotEncoding, para transformarlas en dummies\n",
    "# Para las variables continuas, tengo que normalizarlas, para que esten en el rango entre [0-1].\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_cat=data[['cut','color','clarity']]\n",
    "\n",
    "enc_categorico = OneHotEncoder(drop='first')\n",
    "categorical_dummies = enc_categorico.fit_transform(X_cat)\n",
    "categorical_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c06169b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0      0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1      0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "2      1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3      0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "53935  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "53936  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "53937  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "53938  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "53939  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "        14   15   16  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      1.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "53935  0.0  0.0  0.0  \n",
       "53936  0.0  0.0  0.0  \n",
       "53937  0.0  0.0  0.0  \n",
       "53938  0.0  0.0  0.0  \n",
       "53939  0.0  0.0  0.0  \n",
       "\n",
       "[53940 rows x 17 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_dummies_df = pd.DataFrame(categorical_dummies.toarray())\n",
    "categorical_dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7610858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00623701, 0.51388889, 0.23076923, 0.36778399, 0.06757216,\n",
       "        0.07641509],\n",
       "       [0.002079  , 0.46666667, 0.34615385, 0.36219739, 0.06519525,\n",
       "        0.07264151],\n",
       "       [0.00623701, 0.38611111, 0.42307692, 0.37709497, 0.06910017,\n",
       "        0.07264151],\n",
       "       ...,\n",
       "       [0.1039501 , 0.55      , 0.32692308, 0.52700186, 0.09643463,\n",
       "        0.11194969],\n",
       "       [0.13721414, 0.5       , 0.28846154, 0.5726257 , 0.10390492,\n",
       "        0.11761006],\n",
       "       [0.11434511, 0.53333333, 0.23076923, 0.54283054, 0.09966044,\n",
       "        0.11446541]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora trabajamos sobre las variables continuas\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_continua = data[['carat','depth','table','x','y','z']]\n",
    "\n",
    "enc_cotinuo = MinMaxScaler()\n",
    "data_normalizada = enc_cotinuo.fit_transform(X_continua)\n",
    "data_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f7ee666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat_normalizada</th>\n",
       "      <th>depth_normalizada</th>\n",
       "      <th>table_normalizada</th>\n",
       "      <th>x_normalizada</th>\n",
       "      <th>y_normalizada</th>\n",
       "      <th>z_normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.367784</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>0.076415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.362197</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>0.072642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.377095</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.072642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>0.082704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.404097</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>0.086478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.535382</td>\n",
       "      <td>0.097793</td>\n",
       "      <td>0.110063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.529795</td>\n",
       "      <td>0.097623</td>\n",
       "      <td>0.113522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.103950</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.527002</td>\n",
       "      <td>0.096435</td>\n",
       "      <td>0.111950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.137214</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.572626</td>\n",
       "      <td>0.103905</td>\n",
       "      <td>0.117610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.114345</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.542831</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.114465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat_normalizada  depth_normalizada  table_normalizada  x_normalizada  \\\n",
       "0               0.006237           0.513889           0.230769       0.367784   \n",
       "1               0.002079           0.466667           0.346154       0.362197   \n",
       "2               0.006237           0.386111           0.423077       0.377095   \n",
       "3               0.018711           0.538889           0.288462       0.391061   \n",
       "4               0.022869           0.563889           0.288462       0.404097   \n",
       "...                  ...                ...                ...            ...   \n",
       "53935           0.108108           0.494444           0.269231       0.535382   \n",
       "53936           0.108108           0.558333           0.230769       0.529795   \n",
       "53937           0.103950           0.550000           0.326923       0.527002   \n",
       "53938           0.137214           0.500000           0.288462       0.572626   \n",
       "53939           0.114345           0.533333           0.230769       0.542831   \n",
       "\n",
       "       y_normalizada  z_normalizada  \n",
       "0           0.067572       0.076415  \n",
       "1           0.065195       0.072642  \n",
       "2           0.069100       0.072642  \n",
       "3           0.071817       0.082704  \n",
       "4           0.073854       0.086478  \n",
       "...              ...            ...  \n",
       "53935       0.097793       0.110063  \n",
       "53936       0.097623       0.113522  \n",
       "53937       0.096435       0.111950  \n",
       "53938       0.103905       0.117610  \n",
       "53939       0.099660       0.114465  \n",
       "\n",
       "[53940 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalizada_df = pd.DataFrame(data_normalizada, columns=X_continua.columns+'_normalizada')\n",
    "data_normalizada_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e299def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat_normalizada</th>\n",
       "      <th>depth_normalizada</th>\n",
       "      <th>table_normalizada</th>\n",
       "      <th>x_normalizada</th>\n",
       "      <th>y_normalizada</th>\n",
       "      <th>z_normalizada</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.367784</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>0.076415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.362197</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.377095</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat_normalizada  depth_normalizada  table_normalizada  x_normalizada  \\\n",
       "0           0.006237           0.513889           0.230769       0.367784   \n",
       "1           0.002079           0.466667           0.346154       0.362197   \n",
       "2           0.006237           0.386111           0.423077       0.377095   \n",
       "\n",
       "   y_normalizada  z_normalizada    0    1    2    3  ...    7    8    9   10  \\\n",
       "0       0.067572       0.076415  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1       0.065195       0.072642  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2       0.069100       0.072642  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    11   12   13   14   15   16  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora unimos ambos data frame, para trabajar con ese set de datos\n",
    "\n",
    "X = pd.concat([data_normalizada_df,categorical_dummies_df], axis=1)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "288d1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc1496",
   "metadata": {},
   "source": [
    "Otra opción es usar `get_dummies`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac374723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat_normalizada</th>\n",
       "      <th>depth_normalizada</th>\n",
       "      <th>table_normalizada</th>\n",
       "      <th>x_normalizada</th>\n",
       "      <th>y_normalizada</th>\n",
       "      <th>z_normalizada</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.367784</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>0.076415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.362197</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.377095</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat_normalizada  depth_normalizada  table_normalizada  x_normalizada  \\\n",
       "0           0.006237           0.513889           0.230769       0.367784   \n",
       "1           0.002079           0.466667           0.346154       0.362197   \n",
       "2           0.006237           0.386111           0.423077       0.377095   \n",
       "\n",
       "   y_normalizada  z_normalizada    0    1    2    3  ...    7    8    9   10  \\\n",
       "0       0.067572       0.076415  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1       0.065195       0.072642  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2       0.069100       0.072642  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    11   12   13   14   15   16  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies=pd.get_dummies(X, drop_first=True)\n",
    "dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d29ed7",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Separemos el conjunto en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60852e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3, random_state = 117)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbeb55",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Ajustemos una regresión lineal múltiple con los datos del conjunto de entrenamiento usando statsmodels y evaluemos la significancia de cada uno de los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33e200c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.920</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.920</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.896e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 18 Oct 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:21:36</td>     <th>  Log-Likelihood:    </th> <td>-3.1890e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 37758</td>      <th>  AIC:               </th>  <td>6.379e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 37734</td>      <th>  BIC:               </th>  <td>6.381e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>  605.6677</td> <td>  197.624</td> <td>    3.065</td> <td> 0.002</td> <td>  218.319</td> <td>  993.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carat_normalizada</th> <td> 5.448e+04</td> <td>  278.733</td> <td>  195.441</td> <td> 0.000</td> <td> 5.39e+04</td> <td>  5.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth_normalizada</th> <td>-2276.1992</td> <td>  190.657</td> <td>  -11.939</td> <td> 0.000</td> <td>-2649.893</td> <td>-1902.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>table_normalizada</th> <td>-1462.4308</td> <td>  180.744</td> <td>   -8.091</td> <td> 0.000</td> <td>-1816.693</td> <td>-1108.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x_normalizada</th>     <td>-1.094e+04</td> <td>  385.496</td> <td>  -28.384</td> <td> 0.000</td> <td>-1.17e+04</td> <td>-1.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y_normalizada</th>     <td> -420.6904</td> <td> 1142.612</td> <td>   -0.368</td> <td> 0.713</td> <td>-2660.241</td> <td> 1818.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z_normalizada</th>     <td>-1292.3376</td> <td> 1113.978</td> <td>   -1.160</td> <td> 0.246</td> <td>-3475.765</td> <td>  891.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>                 <td>  587.5927</td> <td>   39.948</td> <td>   14.709</td> <td> 0.000</td> <td>  509.294</td> <td>  665.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>                 <td>  829.0476</td> <td>   39.667</td> <td>   20.900</td> <td> 0.000</td> <td>  751.299</td> <td>  906.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>                 <td>  774.2104</td> <td>   38.335</td> <td>   20.196</td> <td> 0.000</td> <td>  699.072</td> <td>  849.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>                 <td>  743.0087</td> <td>   38.300</td> <td>   19.400</td> <td> 0.000</td> <td>  667.940</td> <td>  818.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>                 <td> -226.0425</td> <td>   21.320</td> <td>  -10.602</td> <td> 0.000</td> <td> -267.830</td> <td> -184.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>                 <td> -282.8884</td> <td>   21.535</td> <td>  -13.137</td> <td> 0.000</td> <td> -325.097</td> <td> -240.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>                 <td> -499.0250</td> <td>   21.074</td> <td>  -23.679</td> <td> 0.000</td> <td> -540.331</td> <td> -457.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>                 <td>-1003.0732</td> <td>   22.435</td> <td>  -44.711</td> <td> 0.000</td> <td>-1047.046</td> <td> -959.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>                 <td>-1490.7890</td> <td>   25.157</td> <td>  -59.260</td> <td> 0.000</td> <td>-1540.097</td> <td>-1441.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>                 <td>-2380.4588</td> <td>   31.001</td> <td>  -76.787</td> <td> 0.000</td> <td>-2441.221</td> <td>-2319.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>                <td> 5413.2716</td> <td>   61.065</td> <td>   88.648</td> <td> 0.000</td> <td> 5293.583</td> <td> 5532.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>                <td> 3717.5451</td> <td>   52.300</td> <td>   71.081</td> <td> 0.000</td> <td> 3615.035</td> <td> 3820.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>                <td> 2754.5243</td> <td>   52.503</td> <td>   52.464</td> <td> 0.000</td> <td> 2651.616</td> <td> 2857.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>                <td> 4637.5990</td> <td>   53.388</td> <td>   86.866</td> <td> 0.000</td> <td> 4532.957</td> <td> 4742.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>                <td> 4321.1516</td> <td>   52.574</td> <td>   82.191</td> <td> 0.000</td> <td> 4218.105</td> <td> 4424.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>                <td> 5083.5105</td> <td>   56.464</td> <td>   90.030</td> <td> 0.000</td> <td> 4972.839</td> <td> 5194.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>                <td> 5021.3881</td> <td>   54.958</td> <td>   91.368</td> <td> 0.000</td> <td> 4913.670</td> <td> 5129.107</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10637.428</td> <th>  Durbin-Watson:     </th>  <td>   2.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>310890.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.747</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>16.978</td>   <th>  Cond. No.          </th>  <td>    314.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.920\n",
       "Model:                            OLS   Adj. R-squared:                  0.920\n",
       "Method:                 Least Squares   F-statistic:                 1.896e+04\n",
       "Date:                Mon, 18 Oct 2021   Prob (F-statistic):               0.00\n",
       "Time:                        20:21:36   Log-Likelihood:            -3.1890e+05\n",
       "No. Observations:               37758   AIC:                         6.379e+05\n",
       "Df Residuals:                   37734   BIC:                         6.381e+05\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const               605.6677    197.624      3.065      0.002     218.319     993.017\n",
       "carat_normalizada  5.448e+04    278.733    195.441      0.000    5.39e+04     5.5e+04\n",
       "depth_normalizada -2276.1992    190.657    -11.939      0.000   -2649.893   -1902.505\n",
       "table_normalizada -1462.4308    180.744     -8.091      0.000   -1816.693   -1108.168\n",
       "x_normalizada     -1.094e+04    385.496    -28.384      0.000   -1.17e+04   -1.02e+04\n",
       "y_normalizada      -420.6904   1142.612     -0.368      0.713   -2660.241    1818.860\n",
       "z_normalizada     -1292.3376   1113.978     -1.160      0.246   -3475.765     891.090\n",
       "0                   587.5927     39.948     14.709      0.000     509.294     665.891\n",
       "1                   829.0476     39.667     20.900      0.000     751.299     906.796\n",
       "2                   774.2104     38.335     20.196      0.000     699.072     849.349\n",
       "3                   743.0087     38.300     19.400      0.000     667.940     818.078\n",
       "4                  -226.0425     21.320    -10.602      0.000    -267.830    -184.255\n",
       "5                  -282.8884     21.535    -13.137      0.000    -325.097    -240.680\n",
       "6                  -499.0250     21.074    -23.679      0.000    -540.331    -457.719\n",
       "7                 -1003.0732     22.435    -44.711      0.000   -1047.046    -959.101\n",
       "8                 -1490.7890     25.157    -59.260      0.000   -1540.097   -1441.481\n",
       "9                 -2380.4588     31.001    -76.787      0.000   -2441.221   -2319.696\n",
       "10                 5413.2716     61.065     88.648      0.000    5293.583    5532.960\n",
       "11                 3717.5451     52.300     71.081      0.000    3615.035    3820.055\n",
       "12                 2754.5243     52.503     52.464      0.000    2651.616    2857.432\n",
       "13                 4637.5990     53.388     86.866      0.000    4532.957    4742.241\n",
       "14                 4321.1516     52.574     82.191      0.000    4218.105    4424.199\n",
       "15                 5083.5105     56.464     90.030      0.000    4972.839    5194.182\n",
       "16                 5021.3881     54.958     91.368      0.000    4913.670    5129.107\n",
       "==============================================================================\n",
       "Omnibus:                    10637.428   Durbin-Watson:                   2.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           310890.318\n",
       "Skew:                           0.747   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.978   Cond. No.                         314.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import eval_measures\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train)# Creo una constante para decirle al modelo que no esta obligado a cortar en 0 al eje y\n",
    "\n",
    "model = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58747a75",
   "metadata": {},
   "source": [
    "Conclusion: Observamos que los p-value de y_normalizada y z_normalizada, son muy altos, y por tanto no son estadisticamente significativos, no podemos asegurar que sus coeficientes beta, no son 0, esto quiere decir, que no podemos assegurar que haya una correlacion entre la variable target y estas dos variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6fb64",
   "metadata": {},
   "source": [
    "Vamos a intentar solucionar estre problema, utilizando **regularizacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "092560f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126.6429803257492\n",
      "1137.7066896840538\n"
     ]
    }
   ],
   "source": [
    "sm_prediction_train = model.predict(X_train_sm)\n",
    "print(eval_measures.rmse(y_train, sm_prediction_train))\n",
    "\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "sm_prediction_test = model.predict(X_test_sm)\n",
    "print(eval_measures.rmse(y_test, sm_prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9062aa",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Ajustamos el modelo aplicando regularización de Lasso y validación cruzada para estimar el mejor valor de $\\alpha$ para este problema\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\n",
    "\n",
    "¿Cuál es el mejor valor de $\\alpha$ para este problema?\n",
    "\n",
    "¿Cuál es el score obtenido ($R^2$) para este modelo en entrenamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e6709a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203445764331188\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lmlassocv = LassoCV(alphas=[0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,\\\n",
    "                                        0.05, 0.1, 1, 5, 10], cv=5, normalize = False)\n",
    "\n",
    "modelcv = lmlassocv.fit(X_train, y_train)\n",
    "\n",
    "print(modelcv.score(X_train,y_train))\n",
    "\n",
    "print(modelcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dca1c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_reg_model_params = model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e92d81",
   "metadata": {},
   "source": [
    "## Ejercicio 5 \n",
    "\n",
    "Ajustemos los datos de entrenamiento con una regresión con regularización de Lasso para el valor de $\\alpha$ calculado en el punto anterior usando statsmodels.\n",
    "\n",
    "Usemos scatterplots para mostrar \n",
    "\n",
    "* los valores de los coeficientes de la regresión lineal múltiple obtenidos en el Ejercicio 3, y los valores de los coeficientes de la regresión lineal con regularización de Lasso para el modelo entrenado.\n",
    "\n",
    "* los valores de los residuos en entrenamiento resultado del Ejercicio 3, y los residuos en entrenamiento para el modelo con regularización.\n",
    "\n",
    "https://www.statsmodels.org/0.6.1/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "999a93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = modelcv.alpha_\n",
    "\n",
    "#L1_wt : 0, the fit is ridge regression. 1, the fit is the lasso \n",
    "\n",
    "no_reg_model = sm.OLS(y_train, X_train_sm)\n",
    "\n",
    "reg_model = no_reg_model.fit_regularized(alpha = best_alpha, L1_wt = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ffdad741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                 2028.705746\n",
       "carat_normalizada    40301.655655\n",
       "depth_normalizada    -8055.541752\n",
       "table_normalizada    -4669.494594\n",
       "x_normalizada         1760.041231\n",
       "y_normalizada           52.107994\n",
       "z_normalizada         1824.760609\n",
       "0                      408.439420\n",
       "1                      388.436100\n",
       "2                      399.336250\n",
       "3                      455.645636\n",
       "4                     -289.061997\n",
       "5                     -378.010827\n",
       "6                     -563.307037\n",
       "7                    -1029.372688\n",
       "8                    -1464.653475\n",
       "9                    -2320.159582\n",
       "10                    2919.980513\n",
       "11                    1148.583253\n",
       "12                     211.661349\n",
       "13                    2072.715648\n",
       "14                    1776.976453\n",
       "15                    2621.203392\n",
       "16                    2511.508715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " reg_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c22b2544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.scatterplot(x=reg_model.params, y=no_reg_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68396783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_residuals = y_train - reg_model.fittedvalues\n",
    "\n",
    "linear_residuals = y_train - model.fittedvalues\n",
    "\n",
    "sns.scatterplot(x = reg_residuals, y = linear_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a876b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0eaeca8",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Usandos statsmodels y scikit-learn calculemos la performance en test del modelo construído y comparemos los resultados de las dos bibliotecas usando como métricas el error absoluto medio (MAE) y la raiz del error cuadrático medio (RMSE) \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb904c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887c03f5",
   "metadata": {},
   "source": [
    "Métricas en `statsmodels`\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.tools.eval_measures.rmse.html\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.tools.eval_measures.meanabs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39851c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df1ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c648ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47e36af5",
   "metadata": {},
   "source": [
    "Métricas en `scikit-learn`\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072faf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4a050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac1512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb93b8e",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "https://www.kaggle.com/yogendran/intro-to-linear-ridge-and-lasso-regressions\n",
    "    \n",
    "https://towardsdatascience.com/intro-to-regularization-with-ridge-and-lasso-regression-with-sklearn-edcf4c117b7a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
