{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/csuarezgurruchaga/Desktop/Digital-House/CLASE_39/dsad_2021/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "Running command `conda install --yes nltk=3.5.0`... ok\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Evaluación de modelos e importancia de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**Introducción**\n",
    "\n",
    "La Organización Mundial de la Salud ha estimado que 12 millones de muertes ocurren en todo el mundo, cada año debido a enfermedades del corazón. La mitad de las muertes en los Estados Unidos y otros países desarrollados se deben a enfermedades cardiovasculares. El pronóstico temprano de las enfermedades cardiovasculares puede ayudar a tomar decisiones sobre los cambios en el estilo de vida en pacientes de alto riesgo y, a su vez, reducir las complicaciones. Esta investigación tiene la intención de identificar los factores más relevantes / de riesgo de enfermedad cardíaca, así como predecir el riesgo general mediante distintos modelos de clasificación\n",
    "\n",
    "**Fuente**\n",
    "\n",
    "El conjunto de datos está disponible públicamente en el sitio web de Kaggle (https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset), y proviene de un estudio cardiovascular en curso en residentes de la ciudad de Framingham, Massachusetts. El objetivo de la clasificación es predecir si el paciente tiene riesgo de enfermedad coronaria (CHD) en los próximos 10 años. El conjunto de datos proporciona la información del paciente. Incluye más de 4000 registros y 15 atributos.\n",
    "\n",
    "**Variables**\n",
    "\n",
    "Cada atributo es un factor de riesgo potencial. Hay factores de riesgo demográficos, conductuales y médicos.\n",
    "\n",
    "Demográficos:\n",
    "\n",
    "• Sex: male or female(Nominal)\n",
    "\n",
    "• Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "Behavioral\n",
    "\n",
    "• Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "\n",
    "• Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "Médicos (histórico):\n",
    "\n",
    "• BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "\n",
    "• Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "\n",
    "• Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "\n",
    "• Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "Médicos (actual):\n",
    "\n",
    "• Tot Chol: total cholesterol level (Continuous)\n",
    "\n",
    "• Sys BP: systolic blood pressure (Continuous)\n",
    "\n",
    "• Dia BP: diastolic blood pressure (Continuous)\n",
    "\n",
    "• BMI: Body Mass Index (Continuous)\n",
    "\n",
    "• Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "\n",
    "• Glucose: glucose level (Continuous)\n",
    "\n",
    "Variable a predecir (target):\n",
    "\n",
    "• 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Preparación de datos\n",
    "\n",
    "1.1) Leamos los datos del archivo datasets_222487_478477_framingham.csv\n",
    "\n",
    "1.2) ¿Qué porcentaje de registros hay en cada una de las categorías target?\n",
    "\n",
    "1.3) ¿El dataset tiene datos faltantes?\n",
    "\n",
    "1.4) Usemos `dropna` para eliminar los registros con valores faltantes, y volvamos a calcular el porcentaje de registros hay en cada una de las categorías target \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv('../Data/datasets_222487_478477_framingham.csv')\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
       "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
       "       'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué procentaje de registros hay en cada una de las categorías target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.848042\n",
       "1    0.151958\n",
       "Name: TenYearCHD, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.TenYearCHD.value_counts() / data_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4238 entries, 0 to 4237\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4238 non-null   int64  \n",
      " 1   age              4238 non-null   int64  \n",
      " 2   education        4133 non-null   float64\n",
      " 3   currentSmoker    4238 non-null   int64  \n",
      " 4   cigsPerDay       4209 non-null   float64\n",
      " 5   BPMeds           4185 non-null   float64\n",
      " 6   prevalentStroke  4238 non-null   int64  \n",
      " 7   prevalentHyp     4238 non-null   int64  \n",
      " 8   diabetes         4238 non-null   int64  \n",
      " 9   totChol          4188 non-null   float64\n",
      " 10  sysBP            4238 non-null   float64\n",
      " 11  diaBP            4238 non-null   float64\n",
      " 12  BMI              4219 non-null   float64\n",
      " 13  heartRate        4237 non-null   float64\n",
      " 14  glucose          3850 non-null   float64\n",
      " 15  TenYearCHD       4238 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 529.9 KB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_raw.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.847648\n",
       "1    0.152352\n",
       "Name: TenYearCHD, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.TenYearCHD.value_counts() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso, eliminando los registros que tienen algun valor nulo no cambiamos la proporción de registros en cada una de las categorías target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 int64\n",
       "age                  int64\n",
       "education          float64\n",
       "currentSmoker        int64\n",
       "cigsPerDay         float64\n",
       "BPMeds             float64\n",
       "prevalentStroke      int64\n",
       "prevalentHyp         int64\n",
       "diabetes             int64\n",
       "totChol            float64\n",
       "sysBP              float64\n",
       "diaBP              float64\n",
       "BMI                float64\n",
       "heartRate          float64\n",
       "glucose            float64\n",
       "TenYearCHD           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Train Test Split + StandardScaler\n",
    "\n",
    "Construir los conjuntos de entranamiento y test y usando StandardScaler normalizar las features\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"TenYearCHD\"],axis=1)\n",
    "y=data[\"TenYearCHD\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=717)\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Opcional (pero recomendado)\n",
    "\n",
    "Escribir una función que reciba como parámetros \n",
    "\n",
    "* la instancia de un modelo\n",
    "* X_train, los registros con los valores de las features predictoras en el dataset de entrenamiento;\n",
    "* y_train, los registros con el valor del target en el dataset de entrenamiento;\n",
    "* X_test, los registros con los valores de las features predictoras en el dataset de testing;\n",
    "* y_test, los registros con el valor del target en el dataset de testing;\n",
    "* gridSearch_params, los parámetros para usar en grid search para la instancia del modelo\n",
    "* gridSearch_bagging_params, los parámetros para usar en grid search para bagging\n",
    "\n",
    "La función debe entrenar \n",
    "\n",
    "* El modelo que recibe como parámetro usando X_train, y_train\n",
    "\n",
    "* Grid Search Cross Validation KFold: `cv_KFold = KFold(n_splits=3, shuffle=True, random_state=371)`\n",
    "    \n",
    "\n",
    "* Grid Search CV Stratified KFold: `StratifiedKFold(n_splits=3, shuffle=True, random_state=371)`\n",
    "\n",
    "* Bagging\n",
    "\n",
    "* Bagging Grid Search Stratified Cross Validation: usando como base el mejor estimador devuelto en Grid Search CV Stratified KFold y `StratifiedKFold(n_splits=3, shuffle=True, random_state=371)`\n",
    "\n",
    "Esta función debe devolver alguna estructura de datos, por ejemplo un diccionario, donde después podamos consultar el score en test de cada uno de los modelos, y los valores de media y desvío del score en los entrenamientos con grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_instance, X_train, y_train, X_test, y_test, gridSearch_params, gridSearch_bagging_params):\n",
    "    \n",
    "    # entreno el modelo default\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    \n",
    "    # calculo el score sobre los datos de test\n",
    "    score_default_test = model_instance.score(X_test, y_test)\n",
    "    \n",
    "    # calculo la matriz de confusión\n",
    "    predictions_default = model_instance.predict(X_test)\n",
    "    confusion_matrix_default = metrics.confusion_matrix(y_test, predictions_default)\n",
    "    \n",
    "    ###################################################\n",
    "    \n",
    "    # gridSearch KFold:    \n",
    "    cv_KFold = KFold(n_splits=3, shuffle=True, random_state=371)\n",
    "    grid_search_CV_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_KFold)    \n",
    "    grid_search_CV_KFold_model.fit(X_train, y_train)        \n",
    "    scores_KFold = cross_val_score(model_instance, X_train, y_train, cv=cv_KFold, n_jobs=-1)\n",
    "    mean_score_grid_search_CV_KFold_model = scores_KFold.mean()\n",
    "    std_score_grid_search_CV_KFold_model = scores_KFold.std()\n",
    "        \n",
    "    score_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_score_\n",
    "    params_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_params_\n",
    "    \n",
    "    score_grid_search_CV_KFold_model_test = grid_search_CV_KFold_model.score(X_test, y_test)\n",
    "    predictions_grid_search_CV_KFold_model = grid_search_CV_KFold_model.predict(X_test)    \n",
    "    confusion_matrix_grid_search_CV_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_KFold_model)\n",
    "\n",
    "    ###################################################\n",
    "    \n",
    "    # gridSearch Stratified KFold:    \n",
    "    cv_Stratified_KFold =StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "    grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)    \n",
    "    grid_search_CV_Stratified_KFold_model.fit(X_train, y_train)        \n",
    "    scores_Stratified_KFold = cross_val_score(model_instance, X_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "    mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "    std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "    \n",
    "    score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_score_\n",
    "    params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_params_\n",
    "    \n",
    "    score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model.score(X_test, y_test)\n",
    "    predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.predict(X_test)\n",
    "    confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)\n",
    "\n",
    "    ###################################################\n",
    "    \n",
    "    if gridSearch_bagging_params:\n",
    "\n",
    "        # bagging\n",
    "\n",
    "        bagging_model_default = BaggingClassifier(base_estimator = model_instance)\n",
    "        bagging_model_default.fit(X_train, y_train)\n",
    "        score_bagging_model_default_test =  bagging_model_default.score(X_test, y_test)\n",
    "        \n",
    "        predictions_bagging_model_default = bagging_model_default.predict(X_test)\n",
    "        confusion_matrix_bagging_model_default = metrics.confusion_matrix(y_test, predictions_bagging_model_default)    \n",
    "\n",
    "        ###################################################\n",
    "\n",
    "        # bagging Stratified KFold cross validation usando de base el mejor modelo de gridsearch estratificado\n",
    "        base_estimator_stratified_grid_search = grid_search_CV_Stratified_KFold_model.best_estimator_\n",
    "        cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "        grid_search_bagging_model = GridSearchCV(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                               gridSearch_bagging_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "\n",
    "        grid_search_bagging_model.fit(X_train, y_train)\n",
    "        \n",
    "        score_grid_search_bagging_model_test = grid_search_bagging_model.score(X_test, y_test)\n",
    "        predictions_grid_search_bagging_model = grid_search_bagging_model.predict(X_test)\n",
    "        confusion_matrix_grid_search_bagging_model = metrics.confusion_matrix(y_test, predictions_grid_search_bagging_model)\n",
    "        scores_bagging_Stratified_KFold = cross_val_score(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                                                          X_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "        mean_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.mean()\n",
    "        std_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.std()    \n",
    "        \n",
    "        best_score_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_score_\n",
    "        best_params_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_params_\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        score_bagging_model_default_test = None\n",
    "        confusion_matrix_bagging_model_default = None\n",
    "        mean_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        std_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        confusion_matrix_grid_search_bagging_model = None\n",
    "        best_score_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "        score_grid_search_bagging_model_test = None\n",
    "        best_params_bagging_grid_search_CV_Stratified_KFold_model = None\n",
    "\n",
    "                                                                                                                                     \n",
    "    ###################################################\n",
    "    \n",
    "    \n",
    "    # armo un diccionario con todos los valores de performance que calculé para los modelos\n",
    "    result = {\n",
    "        'default': {\n",
    "            'score': score_default_test,\n",
    "            'confusion_matrix': confusion_matrix_default            \n",
    "        },\n",
    "        'cv_kfold': {\n",
    "            'mean_score_grid_search': mean_score_grid_search_CV_KFold_model,\n",
    "            'std_score_grid_search': std_score_grid_search_CV_KFold_model,\n",
    "            'best_score_grid_search': score_grid_search_CV_KFold_model,\n",
    "            'score': score_grid_search_CV_KFold_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_CV_KFold_model           \n",
    "        },\n",
    "        'cv_stratified_kfold': {\n",
    "            'mean_score_grid_search': mean_score_grid_search_CV_Stratified_KFold_model,\n",
    "            'std_score_grid_search': std_score_grid_search_CV_Stratified_KFold_model,\n",
    "            'best_score_grid_search': score_grid_search_CV_Stratified_KFold_model,\n",
    "            'score': score_grid_search_CV_Stratified_KFold_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_CV_Stratified_KFold_model           \n",
    "        },\n",
    "        'bagging': {\n",
    "            'score': score_bagging_model_default_test,\n",
    "            'confusion_matrix': confusion_matrix_bagging_model_default           \n",
    "        },\n",
    "        'bagging_cv_stratified_kfold': {\n",
    "            'mean_score_grid_search': mean_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'std_score_grid_search': std_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'best_score_grid_search': best_params_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "            'score': score_grid_search_bagging_model_test,\n",
    "            'confusion_matrix': confusion_matrix_grid_search_bagging_model           \n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return result\n",
    "        \n",
    "#           'trained_model_instance': model_instance, \n",
    "#              'score_default': score_default_test,\n",
    "#              'confusion_matrix_default': confusion_matrix_default,\n",
    "#              'mean_score_grid_search_CV_KFold_model': mean_score_grid_search_CV_KFold_model, \n",
    "#              'std_score_grid_search_CV_KFold_model': std_score_grid_search_CV_KFold_model, \n",
    "#              'best_score_grid_search_CV_KFold_model': score_grid_search_CV_KFold_model,\n",
    "#              'best_params_grid_search_CV_KFold_model': params_grid_search_CV_KFold_model,              \n",
    "#              'score_grid_search_CV_KFold_model_test': score_grid_search_CV_KFold_model_test,\n",
    "#              'confusion_matrix_grid_search_CV_KFold_model': confusion_matrix_grid_search_CV_KFold_model,\n",
    "        \n",
    "#              'mean_score_grid_search_CV_Stratified_KFold_model': mean_score_grid_search_CV_Stratified_KFold_model, \n",
    "#              'std_score_grid_search_CV_Stratified_KFold_model': std_score_grid_search_CV_Stratified_KFold_model, \n",
    "#              'best_score_grid_search_CV_Stratified_KFold_model': score_grid_search_CV_Stratified_KFold_model,\n",
    "#              'best_params_grid_search_CV_Stratified_KFold_model': params_grid_search_CV_Stratified_KFold_model,              \n",
    "#              'score_grid_search_CV_Stratified_KFold_model_test': score_grid_search_CV_Stratified_KFold_model_test,\n",
    "#              'confusion_matrix_grid_search_CV_Stratified_KFold_model': confusion_matrix_grid_search_CV_Stratified_KFold_model,\n",
    "        \n",
    "#              'score_bagging_default': score_bagging_model_default_test,\n",
    "#              'confusion_matrix_bagging_default': confusion_matrix_bagging_model_default,\n",
    "        \n",
    "#              'mean_score_bagging_grid_search_CV_Stratified_KFold_model': mean_score_bagging_grid_search_CV_Stratified_KFold_model, \n",
    "#              'std_score_bagging_grid_search_CV__StratifiedKFold_model': std_score_bagging_grid_search_CV_Stratified_KFold_model, \n",
    "#              'best_score_bagging_grid_search_CV_Stratified_KFold_model': best_score_bagging_grid_search_CV_Stratified_KFold_model,\n",
    "#              'best_params_bagging_grid_search_CV_Stratified_KFold_model': best_params_bagging_grid_search_CV_Stratified_KFold_model,              \n",
    "#              'score_bagging_grid_search_CV_Stratified_KFold_model_test': score_grid_search_bagging_model_test,\n",
    "#              'confusion_matrix_bagging_grid_search_CV_Stratified_KFold_model': confusion_matrix_grid_search_bagging_model,\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Entrenar un modelo de clasificación basado en árboles, usando bagging y grid search cross validation estratificado sobre los parámetros de bagging, y calcular el score en test de cada uno de los modelos, y los valores de media y desvío del score en los entrenamientos con grid search cross validation.\n",
    "\n",
    "Los parámetros de GridSearchCV que vamos a probar son \n",
    "\n",
    "``params =  {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}``\n",
    "\n",
    "Los parámetros de bagging que vamos a probar son\n",
    "\n",
    "<code>\n",
    "bagging_params = {'n_estimators': [10, 100],\n",
    "\n",
    "                  'max_samples': [0.01, 1.0],\n",
    "                  \n",
    "                  'max_features': [0.3, 1.0],\n",
    "                  \n",
    "                  'bootstrap_features': [True, False]}\n",
    "</code>\n",
    "\n",
    "Si resolvieron el ejercicio 3, pueden usar esa función. \n",
    "\n",
    "Si no, pueden hacer cada uno de los entrenamientos en la misma forma que venimos haciendo en las prácticas anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = DecisionTreeClassifier()\n",
    "x_train = X_train_sc\n",
    "x_test =  X_test_sc\n",
    "gridSearch_params = {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "gridSearch_bagging_params = {'n_estimators': [10, 100],\n",
    "                  'max_samples': [0.01, 1.0],                  \n",
    "                  'max_features': [0.3, 1.0],                  \n",
    "                  'bootstrap_features': [True, False]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': {'score': 0.7584320875113947,\n",
       "  'confusion_matrix': array([[788, 144],\n",
       "         [121,  44]])},\n",
       " 'cv_kfold': {'mean_score_grid_search': 0.7592809691285658,\n",
       "  'std_score_grid_search': 0.018593790157671475,\n",
       "  'best_score_grid_search': 0.8464243845252053,\n",
       "  'score': 0.8477666362807658,\n",
       "  'confusion_matrix': array([[923,   9],\n",
       "         [158,   7]])},\n",
       " 'cv_stratified_kfold': {'mean_score_grid_search': 0.7674872997264556,\n",
       "  'std_score_grid_search': 0.007184359636909028,\n",
       "  'best_score_grid_search': 0.8444704962876123,\n",
       "  'score': 0.8495897903372835,\n",
       "  'confusion_matrix': array([[923,   9],\n",
       "         [156,   9]])},\n",
       " 'bagging': {'score': 0.837739288969918,\n",
       "  'confusion_matrix': array([[902,  30],\n",
       "         [148,  17]])},\n",
       " 'bagging_cv_stratified_kfold': {'mean_score_grid_search': 0.8436889409925752,\n",
       "  'std_score_grid_search': 0.0033615964310444385,\n",
       "  'best_score_grid_search': {'bootstrap_features': True,\n",
       "   'max_features': 1.0,\n",
       "   'max_samples': 1.0,\n",
       "   'n_estimators': 10},\n",
       "  'score': 0.8523245214220602,\n",
       "  'confusion_matrix': array([[930,   2],\n",
       "         [160,   5]])}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando la función:\n",
    "\n",
    "decision_tree_metrics = evaluate_model(model_instance, x_train, y_train, x_test, y_test, gridSearch_params, gridSearch_bagging_params)\n",
    "\n",
    "decision_tree_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en la forma clásica\n",
    "\n",
    "model_instance.fit(x_train, y_train)\n",
    "\n",
    "# calculo el score sobre los datos de test\n",
    "score_default_test = model_instance.score(x_test, y_test)\n",
    "\n",
    "# calculo la matriz de confusión\n",
    "predictions_default = model_instance.predict(X_test)\n",
    "confusion_matrix_default = metrics.confusion_matrix(y_test, predictions_default)\n",
    "    \n",
    "###################################################\n",
    "    \n",
    "# gridSearch KFold:    \n",
    "cv_KFold = KFold(n_splits=3, shuffle=True, random_state=371)\n",
    "grid_search_CV_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_KFold)    \n",
    "grid_search_CV_KFold_model.fit(x_train, y_train)        \n",
    "scores_KFold = cross_val_score(model_instance, x_train, y_train, cv=cv_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_KFold_model = scores_KFold.mean()\n",
    "std_score_grid_search_CV_KFold_model = scores_KFold.std()\n",
    "\n",
    "score_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_score_\n",
    "params_grid_search_CV_KFold_model = grid_search_CV_KFold_model.best_params_\n",
    "\n",
    "score_grid_search_CV_KFold_model_test = grid_search_CV_KFold_model.score(X_test, y_test)\n",
    "predictions_grid_search_CV_KFold_model = grid_search_CV_KFold_model.predict(X_test)    \n",
    "confusion_matrix_grid_search_CV_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_KFold_model)\n",
    "\n",
    "###################################################\n",
    "    \n",
    "# gridSearch Stratified KFold:    \n",
    "cv_Stratified_KFold =StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)    \n",
    "grid_search_CV_Stratified_KFold_model.fit(x_train, y_train)        \n",
    "scores_Stratified_KFold = cross_val_score(model_instance, x_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model.score(X_test, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.predict(X_test)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)\n",
    "\n",
    "###################################################\n",
    "\n",
    "# bagging\n",
    "\n",
    "bagging_model_default = BaggingClassifier(base_estimator = model_instance)\n",
    "bagging_model_default.fit(x_train, y_train)\n",
    "score_bagging_model_default_test =  bagging_model_default.score(x_test, y_test)\n",
    "\n",
    "predictions_bagging_model_default = bagging_model_default.predict(x_test)\n",
    "confusion_matrix_bagging_model_default = metrics.confusion_matrix(y_test, predictions_bagging_model_default)    \n",
    "\n",
    "###################################################\n",
    "\n",
    "# bagging Stratified KFold cross validation usando de base el mejor modelo de gridsearch estratificado\n",
    "base_estimator_stratified_grid_search = grid_search_CV_Stratified_KFold_model.best_estimator_\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "grid_search_bagging_model = GridSearchCV(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                       gridSearch_bagging_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "\n",
    "grid_search_bagging_model.fit(x_train, y_train)\n",
    "\n",
    "score_grid_search_bagging_model_test = grid_search_bagging_model.score(x_test, y_test)\n",
    "predictions_grid_search_bagging_model = grid_search_bagging_model.predict(x_test)\n",
    "confusion_matrix_grid_search_bagging_model = metrics.confusion_matrix(y_test, predictions_grid_search_bagging_model)\n",
    "scores_bagging_Stratified_KFold = cross_val_score(BaggingClassifier(base_estimator = base_estimator_stratified_grid_search),\n",
    "                                                  x_train, y_train, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.mean()\n",
    "std_score_bagging_grid_search_CV_Stratified_KFold_model = scores_bagging_Stratified_KFold.std()    \n",
    "\n",
    "best_score_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_score_\n",
    "best_params_bagging_grid_search_CV_Stratified_KFold_model = grid_search_bagging_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 _ Performance\n",
    "\n",
    "En este ejercicio vamos a repasar dos métodos para evaluar la performance de un modelo.\n",
    "\n",
    "* accuracy_score - Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "\n",
    "* classification_report\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "\n",
    "Vamos a evaluarlas sobre el modelo de bagging Stratified KFold cross validation que usa de base el mejor modelo de decision tree resultado gridsearch estratificado `StratifiedKFold(n_splits=3, shuffle=True, random_state=371)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8486782133090246\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       932\n",
      "           1       0.48      0.06      0.11       165\n",
      "\n",
      "    accuracy                           0.85      1097\n",
      "   macro avg       0.67      0.52      0.51      1097\n",
      "weighted avg       0.80      0.85      0.80      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# el mejor modelo de gridsearch estratificado:\n",
    "\n",
    "model_instance = DecisionTreeClassifier()\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=371)\n",
    "grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)    \n",
    "grid_search_CV_Stratified_KFold_model.fit(x_train, y_train)        \n",
    "\n",
    "best_model = grid_search_CV_Stratified_KFold_model.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "print('accuracy:', accuracy)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print('classification_report:', classification_rep)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Feature importance\n",
    "\n",
    "Veamos qué importancia tiene cada una de las features del modelo entrenado en el ejercicio anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.269384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prevalentHyp</td>\n",
       "      <td>0.249093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>0.124906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currentSmoker</td>\n",
       "      <td>0.076510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.067987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sysBP</td>\n",
       "      <td>0.060438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cigsPerDay</td>\n",
       "      <td>0.038741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>totChol</td>\n",
       "      <td>0.038673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>diaBP</td>\n",
       "      <td>0.035421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>heartRate</td>\n",
       "      <td>0.014627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.013284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>0.010936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPMeds</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prevalentStroke</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_names  feature_importance\n",
       "1               age            0.269384\n",
       "7      prevalentHyp            0.249093\n",
       "0              male            0.124906\n",
       "3     currentSmoker            0.076510\n",
       "8          diabetes            0.067987\n",
       "10            sysBP            0.060438\n",
       "4        cigsPerDay            0.038741\n",
       "9           totChol            0.038673\n",
       "11            diaBP            0.035421\n",
       "13        heartRate            0.014627\n",
       "14          glucose            0.013284\n",
       "2         education            0.010936\n",
       "5            BPMeds            0.000000\n",
       "6   prevalentStroke            0.000000\n",
       "12              BMI            0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance = pd.DataFrame({'feature_names': feature_names, 'feature_importance': feature_importance})\n",
    "importance.sort_values(by = 'feature_importance', axis=0, ascending=False, inplace=True)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - Extra\n",
    "\n",
    "Calculen el área bajo la curva como medida de performance de alguno de los clasificadores entrenados\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "Cross Validation\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "StratifiedKFold\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "Grid Search\n",
    "https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "ROC\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n",
    "\n",
    "BaggingClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
