{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccbce60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/csuarezgurruchaga/Desktop/Digital-House/CLASE_44/dsad_2021/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "Running command `conda install --yes nltk=3.5.0`... ok\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0706d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3dbdca",
   "metadata": {},
   "source": [
    "# Descenso gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ea897",
   "metadata": {},
   "source": [
    "Vamos a usar el dataset de propiedades en Boston (https://www.kaggle.com/c/boston-housing) y tratar de predecir el valor de `medv` usando una regresión lineal múltiple.\n",
    "\n",
    "Para eso, vamos a modificar la clase `MyGradientDescent` presentada en el encuentro sincrónico y usarla para entrenar un modelo de regresión lineal múltiple y uno simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18ae7b",
   "metadata": {},
   "source": [
    "Ayuda: \n",
    "\n",
    "<p style=\"font-size:16px;\">\n",
    "$h =  \\beta_0 + \\beta_1. X_1 + \\beta_2. X_2 + \\beta_3. X_3 + ... + \\beta_m. X_m$\n",
    "</p>\n",
    "\n",
    "i es el índice de la fila en el dataset\n",
    "\n",
    "<p style=\"font-size:16px;\">\n",
    "$h_i =  \\beta_0 + \\beta_1. X_{i1} + \\beta_2. X_{i2} + \\beta_3. X_{i3} + ... + \\beta_m. X_{im}$\n",
    "</p>    \n",
    "\n",
    "Update: \n",
    "\n",
    "<p style=\"font-size:16px;\">\n",
    "$\\beta_0 = \\beta_0 - \\alpha \\frac{1}{N} \\sum (h_i - y_i)$\n",
    "</p>    \n",
    "<p style=\"font-size:16px;\">\n",
    "$\\beta_i = \\beta_i - \\alpha \\frac{1}{N} \\sum (h_i - y_i). X_i$\n",
    "</p>    \n",
    "\n",
    "Costo (error cuadrático medio): \n",
    "<p style=\"font-size:16px;\">    \n",
    "$J(\\beta_0, ..., \\beta_m) = \\frac{1}{N} \\sum_{i=1}^N (h_i - y_i)^2  $\n",
    "</p>\n",
    "Gradiente: \n",
    "\n",
    "<p style=\"font-size:16px;\">    \n",
    "$\\frac{\\partial J(\\beta_0, ..., \\beta_m)}{\\partial \\beta_j} = \\frac{2}{N} \\sum_{i=1}^N (h_i - y_i). X_{ij} $\n",
    "</p>    \n",
    "\n",
    "N es el número de observaciones o filas del dataset\n",
    "\n",
    "Entonces \n",
    "\n",
    "$\\beta_0 = \\beta_0 - \\alpha .\\frac{2}{N} \\sum_{i=1}^N (h_i - y_i). X_{i0}$\n",
    "\n",
    "como $X_{i0} = 1$ queda:\n",
    "\n",
    "$\\beta_0 = \\beta_0 - \\alpha .\\frac{2}{N} \\sum_{i=1}^N (h_i - y_i)$\n",
    "\n",
    "$\\beta_1 = \\beta_1 - \\alpha .\\frac{2}{N} \\sum_{i=1}^N (h_i - y_i). X_{i1}$\n",
    "\n",
    "$\\beta_2 = \\beta_2 - \\alpha .\\frac{2}{N} \\sum_{i=1}^N (h_i - y_i). X_{i2}$\n",
    "\n",
    "... \n",
    "\n",
    "$\\beta_j = \\beta_j - \\alpha .\\frac{2}{N} \\sum_{i=1}^N (h_i - y_i). X_{ij}$\n",
    "\n",
    "\n",
    "$\\alpha$ = Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e43e93",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449d7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b3181",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Leer los datos del archivo `Data/boston_data.csv` en un dataframe y construir un heatmap de correlaciones entre sus columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e173c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.961</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>376.94</td>\n",
       "      <td>9.88</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10328</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.927</td>\n",
       "      <td>47.2</td>\n",
       "      <td>6.9320</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.22</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.24</td>\n",
       "      <td>9.97</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.73397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.597</td>\n",
       "      <td>94.9</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>351.85</td>\n",
       "      <td>21.45</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04337</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>6.115</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>393.97</td>\n",
       "      <td>9.43</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.15876   0.0  10.81   0.0  0.413  5.961  17.5  5.2873  4.0  305.0   \n",
       "1  0.10328  25.0   5.13   0.0  0.453  5.927  47.2  6.9320  8.0  284.0   \n",
       "2  0.34940   0.0   9.90   0.0  0.544  5.972  76.7  3.1025  4.0  304.0   \n",
       "3  2.73397   0.0  19.58   0.0  0.871  5.597  94.9  1.5257  5.0  403.0   \n",
       "4  0.04337  21.0   5.64   0.0  0.439  6.115  63.0  6.8147  4.0  243.0   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     19.2  376.94   9.88  21.7  \n",
       "1     19.7  396.90   9.22  19.6  \n",
       "2     18.4  396.24   9.97  20.3  \n",
       "3     14.7  351.85  21.45  15.4  \n",
       "4     16.8  393.97   9.43  20.5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/boston_data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebf33a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4782a9",
   "metadata": {},
   "source": [
    "## Ejercicio 2 \n",
    "\n",
    "La variable target del modelo es `medv`.\n",
    "\n",
    "Seleccionar como variables predictoras las tres variables que tengan mayor correlación (en valor absoluto) con la variable target.\n",
    "\n",
    "Construir los conjuntos de train y test y normalizar las features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "811f0501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chas       0.141400\n",
       "dis        0.264876\n",
       "zn         0.355608\n",
       "black      0.360071\n",
       "age        0.390863\n",
       "crim       0.400956\n",
       "rad        0.423508\n",
       "nox        0.439225\n",
       "tax        0.495792\n",
       "indus      0.501698\n",
       "ptratio    0.506313\n",
       "rm         0.683541\n",
       "lstat      0.742695\n",
       "medv       1.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(data.corr()['medv']).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb53d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['lstat', 'rm', 'ptratio']\n",
    "X_features = data[features]\n",
    "y = data['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d51d7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83ff458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1e057",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Modificar la clase `MyGradientDescent` presentada en el encuentro sincrónico para resolver ahora una regresión **múltiple** usando descenso gradiente.\n",
    "\n",
    "```\n",
    "\n",
    "class MyGradientDescent():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = 0\n",
    "        self.beta0 = 0\n",
    "          \n",
    "    def fit(self, X, y, epochs = 100):\n",
    "        N = len(X)\n",
    "        history = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for i in range(N):\n",
    "                Xi = X[i, :]\n",
    "                yi = y.iloc[i]                 \n",
    "                \n",
    "                hi = self.beta1 * Xi + self.beta0\n",
    "                f = hi - yi\n",
    "                \n",
    "                self.beta1 -= self.learning_rate * 2 / N * f * Xi\n",
    "                self.beta0 -= self.learning_rate * 2 / N * f \n",
    "\n",
    "            loss = 0\n",
    "            loss = mean_squared_error(y, (self.beta1 * X + self.beta0))\n",
    "                                      \n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss})\")\n",
    "            \n",
    "            history.append(loss)\n",
    "                                      \n",
    "        return history\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return self.beta1 * X + self.beta0\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Tener en cuenta las fórmulas presentadas en la ayuda al inicio de la notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48917ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9d745e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientDescentMultiple():\n",
    "    \n",
    "    def __init__(self, learning_rate, m):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.betas = np.repeat(0, m)\n",
    "        self.beta0 = 0\n",
    "          \n",
    "    def fit(self, X, y, epochs = 100):\n",
    "        N = len(X)\n",
    "        m = X.shape[1] \n",
    "        history = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            gradiente_0 = 0\n",
    "            gradiente = np.repeat(0, m)\n",
    "            for i in range(N):\n",
    "                Xi = X[i, :]\n",
    "                yi = y.iloc[i]                 \n",
    "\n",
    "                hi = np.dot(Xi, self.betas) + self.beta0    \n",
    "                \n",
    "                gradiente = gradiente + (hi - yi) * Xi\n",
    "                gradiente_0 = gradiente_0 + (hi - yi)\n",
    "\n",
    "\n",
    "            self.beta0 = self.beta0 - self.learning_rate * 2 / N * gradiente_0   \n",
    "            self.betas = self.betas - self.learning_rate * 2 / N * gradiente\n",
    "                    \n",
    "            pred = np.dot(X, self.betas) + self.beta0\n",
    "            loss = mean_squared_error(y, pred)\n",
    "                                      \n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss})\")\n",
    "            \n",
    "            history.append(loss)\n",
    "                                      \n",
    "        return history\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.betas) + self.beta0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440d5b8",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Entrenar la regresión lineal múltiple con tres variables predictoras usando la clase que definieron en el ejercicio 3.\n",
    "\n",
    "Evaluar la performance en test mediante el error cuadrático medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55fd66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 552.9706208122417)\n",
      "Epoch: 100, Loss: 32.747061639398275)\n",
      "Epoch: 200, Loss: 24.419506634518687)\n",
      "Epoch: 300, Loss: 24.266662635172867)\n",
      "Epoch: 400, Loss: 24.262934296516512)\n",
      "Epoch: 500, Loss: 24.262703056067398)\n",
      "Epoch: 600, Loss: 24.26267212647544)\n",
      "Epoch: 700, Loss: 24.26266719726997)\n",
      "Epoch: 800, Loss: 24.262666392930523)\n",
      "Epoch: 900, Loss: 24.262666261234756)\n"
     ]
    }
   ],
   "source": [
    "model = MyGradientDescentMultiple(learning_rate = 0.01, m = 3)\n",
    "history = model.fit(X_train_scl, y_train, 1000)\n",
    "\n",
    "predictions = model.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd3b2e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.411860260524367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb2b8b",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Graficar el valor de pérdida en función de las épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ad522e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = range(len(history)), y = history);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcddd3",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Usar la misma clase del ejercicio 3 para ajustar una regresión lineal simple cuya variable predictora sea `lstat` y comprobar que esta clase da el mismo resultado que `MyGradientDescent`\n",
    "\n",
    "Graficar en un scatterplot los datos de test y los predichos por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe7dafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['lstat']\n",
    "X_features = data[features]\n",
    "y = data['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b62e94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f64b62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "753b9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 555.245046095597)\n",
      "Epoch: 100, Loss: 45.119871379381145)\n",
      "Epoch: 200, Loss: 36.14781704423795)\n",
      "Epoch: 300, Loss: 35.99001703164781)\n",
      "Epoch: 400, Loss: 35.98724165345199)\n",
      "Epoch: 500, Loss: 35.987192840248476)\n",
      "Epoch: 600, Loss: 35.987191981724465)\n",
      "Epoch: 700, Loss: 35.987191966624785)\n",
      "Epoch: 800, Loss: 35.98719196635921)\n",
      "Epoch: 900, Loss: 35.987191966354544)\n"
     ]
    }
   ],
   "source": [
    "model_simple = MyGradientDescentMultiple(learning_rate = 0.01, m = 1)\n",
    "history = model_simple.fit(X_train_scl, y_train, 1000)\n",
    "\n",
    "predictions = model_simple.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d7f6e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.64073129]\n",
      "22.283828345335326\n"
     ]
    }
   ],
   "source": [
    "print(model_simple.betas)\n",
    "print(model_simple.beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55970f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0087666430629"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa6e26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = range(len(history)), y = history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de96505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X_test_scl[:, 0], y = y_test )\n",
    "sns.lineplot(x = X_test_scl[:, 0], y = predictions, color=\"orange\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e250c",
   "metadata": {},
   "source": [
    "Ahora veamos que devuelve `MyGradientDescent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae6345ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientDescent():\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = 0\n",
    "        self.beta0 = 0\n",
    "          \n",
    "    def fit(self, X, y, epochs = 100):\n",
    "        N = len(X)\n",
    "        history = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for i in range(N):\n",
    "                Xi = X[i, :]\n",
    "                yi = y.iloc[i] \n",
    "                \n",
    "                hi = self.beta1 * Xi + self.beta0\n",
    "                f = hi - yi\n",
    "                \n",
    "                self.beta1 -= self.learning_rate * 2 / N * f * Xi\n",
    "                self.beta0 -= self.learning_rate * 2 / N * f \n",
    "\n",
    "            loss = 0\n",
    "            loss = mean_squared_error(y, (self.beta1 * X + self.beta0))\n",
    "                                      \n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss})\")\n",
    "            \n",
    "            history.append(loss)\n",
    "                                      \n",
    "        return history\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return self.beta1 * X + self.beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b1c1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 555.4547805045436)\n",
      "Epoch: 100, Loss: 45.50154202643327)\n",
      "Epoch: 200, Loss: 36.16170328551317)\n",
      "Epoch: 300, Loss: 35.99042685940659)\n",
      "Epoch: 400, Loss: 35.987256662664166)\n",
      "Epoch: 500, Loss: 35.98719402774878)\n",
      "Epoch: 600, Loss: 35.987192260508245)\n",
      "Epoch: 700, Loss: 35.987192144208066)\n",
      "Epoch: 800, Loss: 35.98719213071977)\n",
      "Epoch: 900, Loss: 35.98719212893573)\n"
     ]
    }
   ],
   "source": [
    "model_lineal_simple = MyGradientDescent(learning_rate = 0.01)\n",
    "history = model_lineal_simple.fit(X_train_scl, y_train, 1000)\n",
    "\n",
    "predictions = model_lineal_simple.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "473bf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.64058089]\n",
      "[22.28345459]\n"
     ]
    }
   ],
   "source": [
    "print(model_lineal_simple.beta1)\n",
    "print(model_lineal_simple.beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f55ab46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.008910136931455"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf9668",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - Opcional\n",
    "\n",
    "Intenten entrenar un modelo con cinco variables predictoras. \n",
    "\n",
    "Posiblemente tengan que probar distintos valores de learning rate para conseguir resultados aceptables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9886fd7",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Implementando de forma más general la clase `MyGradientDescent` logramos usar el mismo código para resolver regresiones lineales simples y múltiples con descenso gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bce149",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "---\n",
    "\n",
    "https://towardsdatascience.com/multivariate-linear-regression-in-python-step-by-step-128c2b127171\n",
    "\n",
    "https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
