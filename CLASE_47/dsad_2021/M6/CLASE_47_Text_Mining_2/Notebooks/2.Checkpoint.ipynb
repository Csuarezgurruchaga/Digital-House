{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/csuarezgurruchaga/Desktop/Digital-House/CLASE_47/dsad_2021/common\n",
      "default checking\n",
      "Running command `conda list`... ok\n",
      "jupyterlab=2.2.6 already installed\n",
      "pandas=1.1.5 already installed\n",
      "bokeh=2.2.3 already installed\n",
      "seaborn=0.11.0 already installed\n",
      "matplotlib=3.3.2 already installed\n",
      "ipywidgets=7.5.1 already installed\n",
      "pytest=6.2.1 already installed\n",
      "chardet=4.0.0 already installed\n",
      "psutil=5.7.2 already installed\n",
      "scipy=1.5.2 already installed\n",
      "statsmodels=0.12.1 already installed\n",
      "scikit-learn=0.23.2 already installed\n",
      "xlrd=2.0.1 already installed\n",
      "nltk=3.5 already installed\n",
      "unidecode=1.1.1 already installed\n",
      "pydotplus=2.0.2 already installed\n",
      "pandas-datareader=0.9.0 already installed\n",
      "flask=1.1.2 already installed\n"
     ]
    }
   ],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Clasificacion de texto\n",
    "\n",
    "Trabajaremos con un dataset de noticias (en ingles) sobre diferentes temas: world, sports, business, sci/tech.\n",
    "\n",
    "La idea es vectorizar el corpus de noticias e implementar un clasificador para identificar a qué tema pertenecen las noticias.\n",
    "\n",
    "Trabajaremos con una versión reducida de un corpus que pueden descargar completo (~30Mb) del siguiente sitio:\n",
    "\n",
    "https://github.com/mhjabreel/CharCnn_Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "\n",
    "Generamos el corpus:\n",
    "\n",
    "Importen los datos con pandas. Los datos se encuentran en '../Data/ag_news_reduced.csv'. \n",
    "\n",
    "El dataset contiene tres columnas: la primera tiene un entero que indica a qué clase pertenece la noticia. La segunda es el título y la tercera es una descripción de la noticia.\n",
    "\n",
    "Como no tenemos las noticias enteras sino solo un resumen, conviene que generemos el corpus concatenando el título y la descripción en un sólo texto. \n",
    "\n",
    "Generen una columna en el dataframe que sea la concatenación del título y la descripción. No olviden agregar un espacio en blanco para no pegar la última palabra del título con la primera de la descrición.\n",
    "\n",
    "¿Cuántos artículos hay de cada clase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Google IPO faces Playboy slip-up</td>\n",
       "      <td>The bidding gets underway for Google's public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Letters</td>\n",
       "      <td>Target the abusers of legal weapons We can all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Oldsmobile: The final parking lot</td>\n",
       "      <td>Why General Motors dropped the Oldsmobile. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>AOL to Sell Cheap PCs to Minorities and Senior...</td>\n",
       "      <td>Reuters - America Online on Thursday said it\\p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class class_name                                              title  \\\n",
       "0      3   Business  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3   Business                   Google IPO faces Playboy slip-up   \n",
       "2      3   Business                                            Letters   \n",
       "3      3   Business                  Oldsmobile: The final parking lot   \n",
       "4      4   Sci/Tech  AOL to Sell Cheap PCs to Minorities and Senior...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  The bidding gets underway for Google's public ...  \n",
       "2  Target the abusers of legal weapons We can all...  \n",
       "3  Why General Motors dropped the Oldsmobile. The...  \n",
       "4  Reuters - America Online on Thursday said it\\p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/ag_news_reduced.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Google IPO faces Playboy slip-up</td>\n",
       "      <td>The bidding gets underway for Google's public ...</td>\n",
       "      <td>Google IPO faces Playboy slip-up The bidding g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Letters</td>\n",
       "      <td>Target the abusers of legal weapons We can all...</td>\n",
       "      <td>Letters Target the abusers of legal weapons We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Oldsmobile: The final parking lot</td>\n",
       "      <td>Why General Motors dropped the Oldsmobile. The...</td>\n",
       "      <td>Oldsmobile: The final parking lot Why General ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>AOL to Sell Cheap PCs to Minorities and Senior...</td>\n",
       "      <td>Reuters - America Online on Thursday said it\\p...</td>\n",
       "      <td>AOL to Sell Cheap PCs to Minorities and Senior...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class class_name                                              title  \\\n",
       "0      3   Business  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3   Business                   Google IPO faces Playboy slip-up   \n",
       "2      3   Business                                            Letters   \n",
       "3      3   Business                  Oldsmobile: The final parking lot   \n",
       "4      4   Sci/Tech  AOL to Sell Cheap PCs to Minorities and Senior...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  The bidding gets underway for Google's public ...   \n",
       "2  Target the abusers of legal weapons We can all...   \n",
       "3  Why General Motors dropped the Oldsmobile. The...   \n",
       "4  Reuters - America Online on Thursday said it\\p...   \n",
       "\n",
       "                                              corpus  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...  \n",
       "1  Google IPO faces Playboy slip-up The bidding g...  \n",
       "2  Letters Target the abusers of legal weapons We...  \n",
       "3  Oldsmobile: The final parking lot Why General ...  \n",
       "4  AOL to Sell Cheap PCs to Minorities and Senior...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus']=df.apply(lambda x :x['title']+' '+x['description'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1539\n",
       "4    1520\n",
       "1    1486\n",
       "3    1455\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "\n",
    "¿Cuáles son las palabras más frecuentes dentro de cada clase?\n",
    "\n",
    "Ayuda: Pueden vectorizar el corpus (dividido por temas) usando CountVectorizer() y luego sumar las filas de la matriz para obtener el número total de veces que aparece cada término.\n",
    "\n",
    "Ayuda2: No olviden remover stopwords al vectorizar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "vectorizer=CountVectorizer(stop_words=stopwords_en, lowercase=True, strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1=df['corpus'][df['class']==1]\n",
    "X_2=df['corpus'][df['class']==2]\n",
    "X_3=df['corpus'][df['class']==3]\n",
    "X_4=df['corpus'][df['class']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39           471\n",
       "said         362\n",
       "iraq         288\n",
       "ap           281\n",
       "reuters      246\n",
       "president    222\n",
       "us           202\n",
       "two          199\n",
       "afp          165\n",
       "minister     163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1_vec=vectorizer.fit_transform(X_1)\n",
    "X_1_vec_df=pd.DataFrame(X_1_vec.todense(), columns = vectorizer.get_feature_names())\n",
    "X_1_vec_df.sum().sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39        709\n",
       "ap        356\n",
       "new       226\n",
       "first     216\n",
       "game      206\n",
       "team      200\n",
       "two       197\n",
       "season    193\n",
       "win       177\n",
       "one       173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_vec=vectorizer.fit_transform(X_2)\n",
    "X_2_vec_df=pd.DataFrame(X_2_vec.todense(), columns = vectorizer.get_feature_names())\n",
    "X_2_vec_df.sum().sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39         611\n",
       "reuters    422\n",
       "said       341\n",
       "oil        332\n",
       "new        310\n",
       "us         279\n",
       "gt         274\n",
       "lt         272\n",
       "stocks     231\n",
       "inc        217\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3_vec=vectorizer.fit_transform(X_3)\n",
    "X_3_vec_df=pd.DataFrame(X_3_vec.todense(), columns = vectorizer.get_feature_names())\n",
    "X_3_vec_df.sum().sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39           458\n",
       "new          348\n",
       "microsoft    287\n",
       "software     211\n",
       "said         204\n",
       "ap           203\n",
       "lt           180\n",
       "gt           179\n",
       "reuters      176\n",
       "internet     172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_4_vec=vectorizer.fit_transform(X_4)\n",
    "X_4_vec_df=pd.DataFrame(X_4_vec.todense(), columns = vectorizer.get_feature_names())\n",
    "X_4_vec_df.sum().sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "\n",
    "Vectorizar el corpus usando Countvectorizer y entrenar un clasificador de tipo Multinomial Naive Bayes (MultinomialNB). Para empezar, hagan un simple train_test_split de los datos y vean la performance (accuracy) en el set de validacion.\n",
    "\n",
    "Luego vean si pueden mejorar esa performance optimizando el parámetro alpha del modelo haciendo una Gridsearch cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.corpus\n",
    "y = df.class_name\n",
    "\n",
    "# vectorizer_tfidf = TfidfTransformer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,random_state = 1203)\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "skf = StratifiedKFold(shuffle = True, random_state=1203)\n",
    "\n",
    "cvs = cross_val_score(mnb, X_train, y_train, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy del set de validacion es:  0.8822222222222222\n"
     ]
    }
   ],
   "source": [
    "print('El accuracy del set de validacion es: ',cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentemos mejorar la performance a partir de gridsearch\n",
    "param_grid = {'alpha':np.arange(0.1,1, 0.1)}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(mnb, param_grid, cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1203, shuffle=True),\n",
       "             estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mnb= gs.best_estimator_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy del set de validacion es:  0.8842222222222222\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(best_mnb, X_train, y_train, cv=skf)\n",
    "print('El accuracy del set de validacion es: ',cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "Repetir lo anterior removiendo stopwords al vectorizar.\n",
    "\n",
    "¿Cambia la performance?  ¿Cuánto se redujo la dimensionalidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Utilizar los parámetros min_df y max_df para remover términos que aparecen en muy pocos documentos o que aparecen en demasiados (stopwords específicas del corpus).\n",
    "\n",
    "Reentrenar el modelo y ver si cambia la performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(stop_words=stopwords_en, \n",
    "                           lowercase=True, \n",
    "                           strip_accents='unicode', \n",
    "                           max_df=100, min_df = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.corpus\n",
    "y = df.class_name\n",
    "\n",
    "# vectorizer_tfidf = TfidfTransformer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,random_state = 1203)\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "skf = StratifiedKFold(shuffle = True, random_state=1203)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':np.arange(0.1,1, 0.1)}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(mnb, param_grid, cv = skf).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy del set de validacion es:  0.8788888888888888\n"
     ]
    }
   ],
   "source": [
    "best_mnb = gs.best_estimator_  \n",
    "cvs = cross_val_score(best_mnb, X_train, y_train, cv=skf)\n",
    "print('El accuracy del set de validacion es: ',cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "Repetir el análisis incluyendo bigramas en la vectorizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en.append('reuters') #removemos tokenz de nuestro vocabulario que no tienen valor y estan entre las mas repetidas\n",
    "stopwords_en.append('39')\n",
    "\n",
    "vectorizer=CountVectorizer(stop_words=stopwords_en, \n",
    "                           lowercase=True, \n",
    "                           strip_accents='unicode', \n",
    "                           max_df=0.8, min_df = 2,\n",
    "                           ngram_range=(1,3))# incluimos bigramas y trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.corpus\n",
    "y = df.class_name\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y,random_state = 1203)\n",
    "\n",
    "\n",
    "X_train = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "skf = StratifiedKFold(shuffle = True, random_state=1203)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':np.arange(0.1,1, 0.1)}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(mnb, param_grid, cv = skf).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy del set de validacion es:  0.8828888888888888\n"
     ]
    }
   ],
   "source": [
    "best_mnb = gs.best_estimator_  \n",
    "cvs = cross_val_score(best_mnb, X_train, y_train, cv=skf)\n",
    "print('El accuracy del set de validacion es: ',cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, best_mnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dhdsblend2021] *",
   "language": "python",
   "name": "conda-env-dhdsblend2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
